{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52211,"status":"ok","timestamp":1708136692358,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"BO6l4Xl70DME","outputId":"6dc15ab9-2aef-4f35-9a5b-992b82bf051d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision\u003e=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.16.0+cu121)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (2.1.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4-\u003esegmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2-\u003esegmentation-models-pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2-\u003esegmentation-models-pytorch) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2-\u003esegmentation-models-pytorch) (0.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision\u003e=0.5.0-\u003esegmentation-models-pytorch) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision\u003e=0.5.0-\u003esegmentation-models-pytorch) (2.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (2.1.0)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-\u003etimm==0.9.2-\u003esegmentation-models-pytorch) (23.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision\u003e=0.5.0-\u003esegmentation-models-pytorch) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision\u003e=0.5.0-\u003esegmentation-models-pytorch) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision\u003e=0.5.0-\u003esegmentation-models-pytorch) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision\u003e=0.5.0-\u003esegmentation-models-pytorch) (2024.2.2)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (2.1.5)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=ded699ea6dd9f50787b508ea551e9d70b2f6cb424f577592e4942f4b746f686d\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=629d43f5f0b27a795a4acd55735238b113d1b7e0a0a00b0eac3160f1981628a7\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n","Collecting git+https://github.com/albumentations-team/albumentations\n","  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-a9g__nf2\n","  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations /tmp/pip-req-build-a9g__nf2\n","  Resolved https://github.com/albumentations-team/albumentations to commit be6a217b207b3d7ebe792caabb438d660b45f2a5\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy\u003e=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.25.2)\n","Requirement already satisfied: scipy\u003e=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.11.4)\n","Collecting scikit-image\u003e=0.21.0 (from albumentations==1.3.1)\n","  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (6.0.1)\n","Requirement already satisfied: qudida\u003e=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.0.4)\n","Requirement already satisfied: opencv-python-headless\u003e=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (4.9.0.80)\n","Requirement already satisfied: scikit-learn\u003e=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida\u003e=0.0.4-\u003ealbumentations==1.3.1) (1.2.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida\u003e=0.0.4-\u003ealbumentations==1.3.1) (4.9.0)\n","Requirement already satisfied: networkx\u003e=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image\u003e=0.21.0-\u003ealbumentations==1.3.1) (3.2.1)\n","Requirement already satisfied: pillow\u003e=9.0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image\u003e=0.21.0-\u003ealbumentations==1.3.1) (9.4.0)\n","Requirement already satisfied: imageio\u003e=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image\u003e=0.21.0-\u003ealbumentations==1.3.1) (2.31.6)\n","Requirement already satisfied: tifffile\u003e=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image\u003e=0.21.0-\u003ealbumentations==1.3.1) (2024.2.12)\n","Requirement already satisfied: packaging\u003e=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image\u003e=0.21.0-\u003ealbumentations==1.3.1) (23.2)\n","Requirement already satisfied: lazy_loader\u003e=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image\u003e=0.21.0-\u003ealbumentations==1.3.1) (0.3)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.19.1-\u003equdida\u003e=0.0.4-\u003ealbumentations==1.3.1) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.19.1-\u003equdida\u003e=0.0.4-\u003ealbumentations==1.3.1) (3.2.0)\n","Installing collected packages: scikit-image\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","Successfully installed scikit-image-0.22.0\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Collecting opencv-contrib-python\n","  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.25.2)\n","Installing collected packages: opencv-contrib-python\n","  Attempting uninstall: opencv-contrib-python\n","    Found existing installation: opencv-contrib-python 4.8.0.76\n","    Uninstalling opencv-contrib-python-4.8.0.76:\n","      Successfully uninstalled opencv-contrib-python-4.8.0.76\n","Successfully installed opencv-contrib-python-4.9.0.80\n","--2024-02-17 02:24:47--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2813 (2.7K) [text/plain]\n","Saving to: ‘helper.py’\n","\n","helper.py           100%[===================\u003e]   2.75K  --.-KB/s    in 0s      \n","\n","2024-02-17 02:24:48 (42.0 MB/s) - ‘helper.py’ saved [2813/2813]\n","\n","--2024-02-17 02:24:49--  https://docs.google.com/uc?export=download\u0026confirm=\u0026id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG\n","Resolving docs.google.com (docs.google.com)... 64.233.188.138, 64.233.188.101, 64.233.188.139, ...\n","Connecting to docs.google.com (docs.google.com)|64.233.188.138|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG\u0026export=download [following]\n","--2024-02-17 02:24:50--  https://drive.usercontent.google.com/download?id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG\u0026export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.125.132, 2404:6800:4008:c01::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.125.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2423 (2.4K) [text/html]\n","Saving to: ‘tmp’\n","\n","tmp                 100%[===================\u003e]   2.37K  --.-KB/s    in 0s      \n","\n","2024-02-17 02:24:51 (25.6 MB/s) - ‘tmp’ saved [2423/2423]\n","\n"]}],"source":["!pip install segmentation-models-pytorch\n","!pip install -U git+https://github.com/albumentations-team/albumentations\n","!pip install --upgrade opencv-contrib-python\n","!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download\u0026confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download\u0026id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')\u0026id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG\" -O 'tmp' \u0026\u0026 rm -rf /tmp/cookies.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13721,"status":"ok","timestamp":1708136706075,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"Eeh1TTKP07d_"},"outputs":[],"source":["import torch\n","import cv2\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import helper\n","\n","from torch.utils.data import Dataset\n","import os\n","import numpy as np\n","from glob import glob\n","import tensorflow as tf\n","from torch.utils.data import DataLoader\n","from torch import nn\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.losses import DiceLoss"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708136706075,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"HbGrvBUMYDVf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37630,"status":"ok","timestamp":1708136743700,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"LoTOfFtRYDCr","outputId":"1dfee320-0e6c-438f-8306-308ab06c7a1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708136743700,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"-RqWKzrG0rXf"},"outputs":[],"source":["if not os.path.exists('image'):\n","    os.makedirs('image')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708136743700,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"0ow9ID4J0h4A","outputId":"70cadb68-eeb5-4dcc-f1bb-2ab5a16f6e42"},"outputs":[{"name":"stdout","output_type":"stream","text":["tar: This does not look like a tar archive\n","tar: Skipping to next header\n","tar: Exiting with failure status due to previous errors\n"]}],"source":["!tar -xvf  '/content/tmp' -C '/content/image'"]},{"cell_type":"markdown","metadata":{"id":"swdW2xj815rW"},"source":["## Download file testing enhanment"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4461,"status":"ok","timestamp":1708136748156,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"l97Y1g3y1962","outputId":"452e7d24-65cc-41bf-ed3d-cb292e7c2f1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-02-17 02:25:42--  https://drive.google.com/uc?export=download\u0026id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V\n","Resolving drive.google.com (drive.google.com)... 108.177.97.100, 108.177.97.138, 108.177.97.113, ...\n","Connecting to drive.google.com (drive.google.com)|108.177.97.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V\u0026export=download [following]\n","--2024-02-17 02:25:43--  https://drive.usercontent.google.com/download?id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V\u0026export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.125.132, 2404:6800:4008:c01::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.125.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 21318708 (20M) [application/octet-stream]\n","Saving to: ‘test-im’\n","\n","test-im             100%[===================\u003e]  20.33M  37.3MB/s    in 0.5s    \n","\n","2024-02-17 02:25:47 (37.3 MB/s) - ‘test-im’ saved [21318708/21318708]\n","\n"]}],"source":["!wget \"https://drive.google.com/uc?export=download\u0026id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V\" -O \"test-im\""]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1290,"status":"ok","timestamp":1708136749443,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"4Q3G-MvOPMyT"},"outputs":[],"source":["!cp \"gdrive/MyDrive/test_file.zip\" \"test-im\""]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1708136749443,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"Pm2bKDlj3YjX","outputId":"c50749be-e44d-4839-e810-5f242bf78aff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  test-im\n","  inflating: archive/1 (1).jpg       \n","  inflating: archive/1 (10).jpg      \n","  inflating: archive/1 (100).jpg     \n","  inflating: archive/1 (11).jpg      \n","  inflating: archive/1 (12).jpg      \n","  inflating: archive/1 (13).jpg      \n","  inflating: archive/1 (14).jpg      \n","  inflating: archive/1 (15).jpg      \n","  inflating: archive/1 (16).jpg      \n","  inflating: archive/1 (17).jpg      \n","  inflating: archive/1 (18).jpg      \n","  inflating: archive/1 (19).jpg      \n","  inflating: archive/1 (2).jpg       \n","  inflating: archive/1 (20).jpg      \n","  inflating: archive/1 (21).jpg      \n","  inflating: archive/1 (22).jpg      \n","  inflating: archive/1 (23).jpg      \n","  inflating: archive/1 (24).jpg      \n","  inflating: archive/1 (25).jpg      \n","  inflating: archive/1 (26).jpg      \n","  inflating: archive/1 (27).jpg      \n","  inflating: archive/1 (28).jpg      \n","  inflating: archive/1 (29).jpg      \n","  inflating: archive/1 (3).jpg       \n","  inflating: archive/1 (30).jpg      \n","  inflating: archive/1 (31).jpg      \n","  inflating: archive/1 (32).jpg      \n","  inflating: archive/1 (33).jpg      \n","  inflating: archive/1 (34).jpg      \n","  inflating: archive/1 (35).jpg      \n","  inflating: archive/1 (36).jpg      \n","  inflating: archive/1 (37).jpg      \n","  inflating: archive/1 (38).jpg      \n","  inflating: archive/1 (39).jpg      \n","  inflating: archive/1 (4).jpg       \n","  inflating: archive/1 (40).jpg      \n","  inflating: archive/1 (41).jpg      \n","  inflating: archive/1 (42).jpg      \n","  inflating: archive/1 (43).jpg      \n","  inflating: archive/1 (44).jpg      \n","  inflating: archive/1 (45).jpg      \n","  inflating: archive/1 (46).jpg      \n","  inflating: archive/1 (47).jpg      \n","  inflating: archive/1 (48).jpg      \n","  inflating: archive/1 (49).jpg      \n","  inflating: archive/1 (5).jpg       \n","  inflating: archive/1 (50).jpg      \n","  inflating: archive/1 (51).jpg      \n","  inflating: archive/1 (52).jpg      \n","  inflating: archive/1 (53).jpg      \n","  inflating: archive/1 (54).jpg      \n","  inflating: archive/1 (55).jpg      \n","  inflating: archive/1 (56).jpg      \n","  inflating: archive/1 (57).jpg      \n","  inflating: archive/1 (58).jpg      \n","  inflating: archive/1 (59).jpg      \n","  inflating: archive/1 (6).jpg       \n","  inflating: archive/1 (60).jpg      \n","  inflating: archive/1 (61).jpg      \n","  inflating: archive/1 (62).jpg      \n","  inflating: archive/1 (63).jpg      \n","  inflating: archive/1 (64).jpg      \n","  inflating: archive/1 (65).jpg      \n","  inflating: archive/1 (66).jpg      \n","  inflating: archive/1 (67).jpg      \n","  inflating: archive/1 (68).jpg      \n","  inflating: archive/1 (69).jpg      \n","  inflating: archive/1 (7).jpg       \n","  inflating: archive/1 (70).jpg      \n","  inflating: archive/1 (71).jpg      \n","  inflating: archive/1 (72).jpg      \n","  inflating: archive/1 (73).jpg      \n","  inflating: archive/1 (74).jpg      \n","  inflating: archive/1 (75).jpg      \n","  inflating: archive/1 (76).jpg      \n","  inflating: archive/1 (77).jpg      \n","  inflating: archive/1 (78).jpg      \n","  inflating: archive/1 (79).jpg      \n","  inflating: archive/1 (8).jpg       \n","  inflating: archive/1 (80).jpg      \n","  inflating: archive/1 (81).jpg      \n","  inflating: archive/1 (82).jpg      \n","  inflating: archive/1 (83).jpg      \n","  inflating: archive/1 (84).jpg      \n","  inflating: archive/1 (85).jpg      \n","  inflating: archive/1 (86).jpg      \n","  inflating: archive/1 (87).jpg      \n","  inflating: archive/1 (88).jpg      \n","  inflating: archive/1 (89).jpg      \n","  inflating: archive/1 (9).jpg       \n","  inflating: archive/1 (90).jpg      \n","  inflating: archive/1 (91).jpg      \n","  inflating: archive/1 (92).jpg      \n","  inflating: archive/1 (93).jpg      \n","  inflating: archive/1 (94).jpg      \n","  inflating: archive/1 (95).jpg      \n","  inflating: archive/1 (96).jpg      \n","  inflating: archive/1 (97).jpg      \n","  inflating: archive/1 (98).jpg      \n","  inflating: archive/1 (99).jpg      \n"]}],"source":["!unzip 'test-im' -d 'archive'"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1802,"status":"ok","timestamp":1708136751240,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"Q599bDvnD39F","outputId":"e6a936fd-4bc4-4436-dcd2-b081ec7f7a63"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-02-17 02:25:48--  https://drive.google.com/uc?export=download\u0026id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG\n","Resolving drive.google.com (drive.google.com)... 108.177.97.100, 108.177.97.138, 108.177.97.113, ...\n","Connecting to drive.google.com (drive.google.com)|108.177.97.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG\u0026export=download [following]\n","--2024-02-17 02:25:49--  https://drive.usercontent.google.com/download?id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG\u0026export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.125.132, 2404:6800:4008:c01::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.125.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 387773 (379K) [application/octet-stream]\n","Saving to: ‘test-mark’\n","\n","test-mark           100%[===================\u003e] 378.68K  --.-KB/s    in 0.004s  \n","\n","2024-02-17 02:25:50 (86.1 MB/s) - ‘test-mark’ saved [387773/387773]\n","\n"]}],"source":["!wget 'https://drive.google.com/uc?export=download\u0026id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG' -O \"test-mark\""]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708136751240,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"HxBmWIl9PY0m"},"outputs":[],"source":["!cp \"gdrive/MyDrive/test-markup.zip\" \"test-mark\""]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":733,"status":"ok","timestamp":1708136751970,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"GkTwNWpUEFyE","outputId":"894491ea-4bda-4d90-8869-d8d23474eeec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  test-mark\n","  inflating: markup/1 (1).jpg        \n","  inflating: markup/1 (10).jpg       \n","  inflating: markup/1 (100).jpg      \n","  inflating: markup/1 (11).jpg       \n","  inflating: markup/1 (12).jpg       \n","  inflating: markup/1 (13).jpg       \n","  inflating: markup/1 (14).jpg       \n","  inflating: markup/1 (15).jpg       \n","  inflating: markup/1 (16).jpg       \n","  inflating: markup/1 (17).jpg       \n","  inflating: markup/1 (18).jpg       \n","  inflating: markup/1 (19).jpg       \n","  inflating: markup/1 (2).jpg        \n","  inflating: markup/1 (20).jpg       \n","  inflating: markup/1 (21).jpg       \n","  inflating: markup/1 (22).jpg       \n","  inflating: markup/1 (23).jpg       \n","  inflating: markup/1 (24).jpg       \n","  inflating: markup/1 (25).jpg       \n","  inflating: markup/1 (26).jpg       \n","  inflating: markup/1 (27).jpg       \n","  inflating: markup/1 (28).jpg       \n","  inflating: markup/1 (29).jpg       \n","  inflating: markup/1 (3).jpg        \n","  inflating: markup/1 (30).jpg       \n","  inflating: markup/1 (31).jpg       \n","  inflating: markup/1 (32).jpg       \n","  inflating: markup/1 (33).jpg       \n","  inflating: markup/1 (34).jpg       \n","  inflating: markup/1 (35).jpg       \n","  inflating: markup/1 (36).jpg       \n","  inflating: markup/1 (37).jpg       \n","  inflating: markup/1 (38).jpg       \n","  inflating: markup/1 (39).jpg       \n","  inflating: markup/1 (4).jpg        \n","  inflating: markup/1 (40).jpg       \n","  inflating: markup/1 (41).jpg       \n","  inflating: markup/1 (42).jpg       \n","  inflating: markup/1 (43).jpg       \n","  inflating: markup/1 (44).jpg       \n","  inflating: markup/1 (45).jpg       \n","  inflating: markup/1 (46).jpg       \n","  inflating: markup/1 (47).jpg       \n","  inflating: markup/1 (48).jpg       \n","  inflating: markup/1 (49).jpg       \n","  inflating: markup/1 (5).jpg        \n","  inflating: markup/1 (50).jpg       \n","  inflating: markup/1 (51).jpg       \n","  inflating: markup/1 (52).jpg       \n","  inflating: markup/1 (53).jpg       \n","  inflating: markup/1 (54).jpg       \n","  inflating: markup/1 (55).jpg       \n","  inflating: markup/1 (56).jpg       \n","  inflating: markup/1 (57).jpg       \n","  inflating: markup/1 (58).jpg       \n","  inflating: markup/1 (59).jpg       \n","  inflating: markup/1 (6).jpg        \n","  inflating: markup/1 (60).jpg       \n","  inflating: markup/1 (61).jpg       \n","  inflating: markup/1 (62).jpg       \n","  inflating: markup/1 (63).jpg       \n","  inflating: markup/1 (64).jpg       \n","  inflating: markup/1 (65).jpg       \n","  inflating: markup/1 (66).jpg       \n","  inflating: markup/1 (67).jpg       \n","  inflating: markup/1 (68).jpg       \n","  inflating: markup/1 (69).jpg       \n","  inflating: markup/1 (7).jpg        \n","  inflating: markup/1 (70).jpg       \n","  inflating: markup/1 (71).jpg       \n","  inflating: markup/1 (72).jpg       \n","  inflating: markup/1 (73).jpg       \n","  inflating: markup/1 (74).jpg       \n","  inflating: markup/1 (75).jpg       \n","  inflating: markup/1 (76).jpg       \n","  inflating: markup/1 (77).jpg       \n","  inflating: markup/1 (78).jpg       \n","  inflating: markup/1 (79).jpg       \n","  inflating: markup/1 (8).jpg        \n","  inflating: markup/1 (80).jpg       \n","  inflating: markup/1 (81).jpg       \n","  inflating: markup/1 (82).jpg       \n","  inflating: markup/1 (83).jpg       \n","  inflating: markup/1 (84).jpg       \n","  inflating: markup/1 (85).jpg       \n","  inflating: markup/1 (86).jpg       \n","  inflating: markup/1 (87).jpg       \n","  inflating: markup/1 (88).jpg       \n","  inflating: markup/1 (89).jpg       \n","  inflating: markup/1 (9).jpg        \n","  inflating: markup/1 (90).jpg       \n","  inflating: markup/1 (91).jpg       \n","  inflating: markup/1 (92).jpg       \n","  inflating: markup/1 (93).jpg       \n","  inflating: markup/1 (94).jpg       \n","  inflating: markup/1 (95).jpg       \n","  inflating: markup/1 (96).jpg       \n","  inflating: markup/1 (97).jpg       \n","  inflating: markup/1 (98).jpg       \n","  inflating: markup/1 (99).jpg       \n"]}],"source":["!unzip \"test-mark\" -d \"markup\""]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3358,"status":"ok","timestamp":1708136755323,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"5sJahuhiu-M9","outputId":"f957659b-089b-4ce4-8aaf-47da06fe53d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-02-17 02:25:51--  https://drive.google.com/uc?export=download\u0026id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx\n","Resolving drive.google.com (drive.google.com)... 108.177.97.100, 108.177.97.138, 108.177.97.113, ...\n","Connecting to drive.google.com (drive.google.com)|108.177.97.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx\u0026export=download [following]\n","--2024-02-17 02:25:52--  https://drive.usercontent.google.com/download?id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx\u0026export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.125.132, 2404:6800:4008:c01::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.125.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1109365 (1.1M) [application/octet-stream]\n","Saving to: ‘face-mark’\n","\n","face-mark           100%[===================\u003e]   1.06M  --.-KB/s    in 0.01s   \n","\n","2024-02-17 02:25:54 (104 MB/s) - ‘face-mark’ saved [1109365/1109365]\n","\n"]}],"source":["!wget \"https://drive.google.com/uc?export=download\u0026id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx\" -O \"face-mark\""]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":684,"status":"ok","timestamp":1708136756003,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"jTsPGGpaPj8u"},"outputs":[],"source":["!cp \"gdrive/MyDrive/face_marker.zip\" \"face-mark\""]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708136756003,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"TmqMzUs2vLVk","outputId":"6bdc13cd-2f49-4a5f-e481-578c466d6bee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  face-mark\n","  inflating: face-m/1 (1).jpg        \n","  inflating: face-m/1 (10).jpg       \n","  inflating: face-m/1 (100).jpg      \n","  inflating: face-m/1 (11).jpg       \n","  inflating: face-m/1 (12).jpg       \n","  inflating: face-m/1 (13).jpg       \n","  inflating: face-m/1 (14).jpg       \n","  inflating: face-m/1 (15).jpg       \n","  inflating: face-m/1 (16).jpg       \n","  inflating: face-m/1 (17).jpg       \n","  inflating: face-m/1 (18).jpg       \n","  inflating: face-m/1 (19).jpg       \n","  inflating: face-m/1 (2).jpg        \n","  inflating: face-m/1 (20).jpg       \n","  inflating: face-m/1 (21).jpg       \n","  inflating: face-m/1 (22).jpg       \n","  inflating: face-m/1 (23).jpg       \n","  inflating: face-m/1 (24).jpg       \n","  inflating: face-m/1 (25).jpg       \n","  inflating: face-m/1 (26).jpg       \n","  inflating: face-m/1 (27).jpg       \n","  inflating: face-m/1 (28).jpg       \n","  inflating: face-m/1 (29).jpg       \n","  inflating: face-m/1 (3).jpg        \n","  inflating: face-m/1 (30).jpg       \n","  inflating: face-m/1 (31).jpg       \n","  inflating: face-m/1 (32).jpg       \n","  inflating: face-m/1 (33).jpg       \n","  inflating: face-m/1 (34).jpg       \n","  inflating: face-m/1 (35).jpg       \n","  inflating: face-m/1 (36).jpg       \n","  inflating: face-m/1 (37).jpg       \n","  inflating: face-m/1 (38).jpg       \n","  inflating: face-m/1 (39).jpg       \n","  inflating: face-m/1 (4).jpg        \n","  inflating: face-m/1 (40).jpg       \n","  inflating: face-m/1 (41).jpg       \n","  inflating: face-m/1 (42).jpg       \n","  inflating: face-m/1 (43).jpg       \n","  inflating: face-m/1 (44).jpg       \n","  inflating: face-m/1 (45).jpg       \n","  inflating: face-m/1 (46).jpg       \n","  inflating: face-m/1 (47).jpg       \n","  inflating: face-m/1 (48).jpg       \n","  inflating: face-m/1 (49).jpg       \n","  inflating: face-m/1 (5).jpg        \n","  inflating: face-m/1 (50).jpg       \n","  inflating: face-m/1 (51).jpg       \n","  inflating: face-m/1 (52).jpg       \n","  inflating: face-m/1 (53).jpg       \n","  inflating: face-m/1 (54).jpg       \n","  inflating: face-m/1 (55).jpg       \n","  inflating: face-m/1 (56).jpg       \n","  inflating: face-m/1 (57).jpg       \n","  inflating: face-m/1 (58).jpg       \n","  inflating: face-m/1 (59).jpg       \n","  inflating: face-m/1 (6).jpg        \n","  inflating: face-m/1 (60).jpg       \n","  inflating: face-m/1 (61).jpg       \n","  inflating: face-m/1 (62).jpg       \n","  inflating: face-m/1 (63).jpg       \n","  inflating: face-m/1 (64).jpg       \n","  inflating: face-m/1 (65).jpg       \n","  inflating: face-m/1 (66).jpg       \n","  inflating: face-m/1 (67).jpg       \n","  inflating: face-m/1 (68).jpg       \n","  inflating: face-m/1 (69).jpg       \n","  inflating: face-m/1 (7).jpg        \n","  inflating: face-m/1 (70).jpg       \n","  inflating: face-m/1 (71).jpg       \n","  inflating: face-m/1 (72).jpg       \n","  inflating: face-m/1 (73).jpg       \n","  inflating: face-m/1 (74).jpg       \n","  inflating: face-m/1 (75).jpg       \n","  inflating: face-m/1 (76).jpg       \n","  inflating: face-m/1 (77).jpg       \n","  inflating: face-m/1 (78).jpg       \n","  inflating: face-m/1 (79).jpg       \n","  inflating: face-m/1 (8).jpg        \n","  inflating: face-m/1 (80).jpg       \n","  inflating: face-m/1 (81).jpg       \n","  inflating: face-m/1 (82).jpg       \n","  inflating: face-m/1 (83).jpg       \n","  inflating: face-m/1 (84).jpg       \n","  inflating: face-m/1 (85).jpg       \n","  inflating: face-m/1 (86).jpg       \n","  inflating: face-m/1 (87).jpg       \n","  inflating: face-m/1 (88).jpg       \n","  inflating: face-m/1 (89).jpg       \n","  inflating: face-m/1 (9).jpg        \n","  inflating: face-m/1 (90).jpg       \n","  inflating: face-m/1 (91).jpg       \n","  inflating: face-m/1 (92).jpg       \n","  inflating: face-m/1 (93).jpg       \n","  inflating: face-m/1 (94).jpg       \n","  inflating: face-m/1 (95).jpg       \n","  inflating: face-m/1 (96).jpg       \n","  inflating: face-m/1 (97).jpg       \n","  inflating: face-m/1 (98).jpg       \n","  inflating: face-m/1 (99).jpg       \n"]}],"source":["!unzip \"face-mark\" -d 'face-m'"]},{"cell_type":"markdown","metadata":{"id":"rI2Vgh-f3z9c"},"source":["## Initialize Model"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708136792041,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"dGGRuVzH3mze"},"outputs":[],"source":["DATA_DIR = \"image/LaPa\"\n","DEVICE = 'cpu'\n","ENCODER = 'mobilenet_v2'\n","WEIGHTS = 'imagenet'\n","IMAGE_SIZE = 224\n","num_classes = 11\n","BATCH_SIZE = 64"]},{"cell_type":"markdown","metadata":{"id":"CDd540hZdlya"},"source":["# loading model from drive"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6192,"status":"ok","timestamp":1708136829959,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"BuyQF8Hu3rxD","outputId":"62600ad2-ad87-409e-8f33-9a51e79b4467"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1-MzlRCABoTDNtOCyIM37A611e2Lpjh8u\n","To: /content/best_model\n","100% 17.8M/17.8M [00:00\u003c00:00, 43.6MB/s]\n"]}],"source":["!gdown --id \"1-MzlRCABoTDNtOCyIM37A611e2Lpjh8u\" -O \"best_model\""]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1708136832072,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"3c2YYCc9Lr6q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":802,"status":"ok","timestamp":1708136833900,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"PqvGGHd53_z8"},"outputs":[],"source":["class SegmentationModel(nn.Module):\n","  def __init__(self):\n","    super(SegmentationModel,self).__init__()\n","\n","    self.arc = smp.DeepLabV3Plus(\n","        encoder_name = ENCODER,\n","        encoder_weights = WEIGHTS,\n","        in_channels = 3,\n","        classes = num_classes,\n","        activation = None\n","    )\n","    for param in self.arc.encoder.parameters():\n","        param.requires_grad = False\n","  def forward(self, images, masks = None):\n","    logits = self.arc(images)\n","\n","    if masks != None:\n","      loss1 = DiceLoss(mode=\"multiclass\")(logits,masks)\n","      loss2 = nn.CrossEntropyLoss()(logits,masks)\n","      return logits, loss1 + loss2\n","\n","\n","    return logits"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708136833901,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"Siu307Rz4NT7","outputId":"45ede145-1309-40eb-e69f-ba586a9a85e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n","100%|██████████| 13.6M/13.6M [00:00\u003c00:00, 205MB/s]\n"]},{"data":{"text/plain":["SegmentationModel(\n","  (arc): DeepLabV3Plus(\n","    (encoder): MobileNetV2Encoder(\n","      (features): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (4): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (5): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (6): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (7): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (8): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (9): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (10): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (11): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (12): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (13): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (14): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (15): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (16): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (17): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (18): Conv2dNormActivation(\n","          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","      )\n","    )\n","    (decoder): DeepLabV3PlusDecoder(\n","      (aspp): Sequential(\n","        (0): ASPP(\n","          (convs): ModuleList(\n","            (0): Sequential(\n","              (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (1): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (2): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (3): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (4): ASPPPooling(\n","              (0): AdaptiveAvgPool2d(output_size=1)\n","              (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (3): ReLU()\n","            )\n","          )\n","          (project): Sequential(\n","            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU()\n","            (3): Dropout(p=0.5, inplace=False)\n","          )\n","        )\n","        (1): SeparableConv2d(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU()\n","      )\n","      (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (block1): Sequential(\n","        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (block2): Sequential(\n","        (0): SeparableConv2d(\n","          (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n","          (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (segmentation_head): SegmentationHead(\n","      (0): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n","      (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","  )\n",")"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model = SegmentationModel()\n","model.to(DEVICE)\n"]},{"cell_type":"markdown","metadata":{"id":"-Lmac7pDdpjT"},"source":["# load directly from my drive or you can load model parameter from disk in colab if !wget work"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2027,"status":"ok","timestamp":1708136863346,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"8PooShVhFqwM","outputId":"e1c3c238-6572-4ca1-dd84-b5902a1e0685"},"outputs":[{"data":{"text/plain":["\u003cAll keys matched successfully\u003e"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('gdrive/MyDrive/model4.pt',map_location=torch.device(DEVICE)))"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2258,"status":"ok","timestamp":1708136869545,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"FqkDQBgX4w9u","outputId":"0198cbc6-ec18-4ad7-926f-08b067d95198"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 112, 112]             864\n","       BatchNorm2d-2         [-1, 32, 112, 112]              64\n","             ReLU6-3         [-1, 32, 112, 112]               0\n","            Conv2d-4         [-1, 32, 112, 112]             288\n","       BatchNorm2d-5         [-1, 32, 112, 112]              64\n","             ReLU6-6         [-1, 32, 112, 112]               0\n","            Conv2d-7         [-1, 16, 112, 112]             512\n","       BatchNorm2d-8         [-1, 16, 112, 112]              32\n","  InvertedResidual-9         [-1, 16, 112, 112]               0\n","           Conv2d-10         [-1, 96, 112, 112]           1,536\n","      BatchNorm2d-11         [-1, 96, 112, 112]             192\n","            ReLU6-12         [-1, 96, 112, 112]               0\n","           Conv2d-13           [-1, 96, 56, 56]             864\n","      BatchNorm2d-14           [-1, 96, 56, 56]             192\n","            ReLU6-15           [-1, 96, 56, 56]               0\n","           Conv2d-16           [-1, 24, 56, 56]           2,304\n","      BatchNorm2d-17           [-1, 24, 56, 56]              48\n"," InvertedResidual-18           [-1, 24, 56, 56]               0\n","           Conv2d-19          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-20          [-1, 144, 56, 56]             288\n","            ReLU6-21          [-1, 144, 56, 56]               0\n","           Conv2d-22          [-1, 144, 56, 56]           1,296\n","      BatchNorm2d-23          [-1, 144, 56, 56]             288\n","            ReLU6-24          [-1, 144, 56, 56]               0\n","           Conv2d-25           [-1, 24, 56, 56]           3,456\n","      BatchNorm2d-26           [-1, 24, 56, 56]              48\n"," InvertedResidual-27           [-1, 24, 56, 56]               0\n","           Conv2d-28          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-29          [-1, 144, 56, 56]             288\n","            ReLU6-30          [-1, 144, 56, 56]               0\n","           Conv2d-31          [-1, 144, 28, 28]           1,296\n","      BatchNorm2d-32          [-1, 144, 28, 28]             288\n","            ReLU6-33          [-1, 144, 28, 28]               0\n","           Conv2d-34           [-1, 32, 28, 28]           4,608\n","      BatchNorm2d-35           [-1, 32, 28, 28]              64\n"," InvertedResidual-36           [-1, 32, 28, 28]               0\n","           Conv2d-37          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-38          [-1, 192, 28, 28]             384\n","            ReLU6-39          [-1, 192, 28, 28]               0\n","           Conv2d-40          [-1, 192, 28, 28]           1,728\n","      BatchNorm2d-41          [-1, 192, 28, 28]             384\n","            ReLU6-42          [-1, 192, 28, 28]               0\n","           Conv2d-43           [-1, 32, 28, 28]           6,144\n","      BatchNorm2d-44           [-1, 32, 28, 28]              64\n"," InvertedResidual-45           [-1, 32, 28, 28]               0\n","           Conv2d-46          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-47          [-1, 192, 28, 28]             384\n","            ReLU6-48          [-1, 192, 28, 28]               0\n","           Conv2d-49          [-1, 192, 28, 28]           1,728\n","      BatchNorm2d-50          [-1, 192, 28, 28]             384\n","            ReLU6-51          [-1, 192, 28, 28]               0\n","           Conv2d-52           [-1, 32, 28, 28]           6,144\n","      BatchNorm2d-53           [-1, 32, 28, 28]              64\n"," InvertedResidual-54           [-1, 32, 28, 28]               0\n","           Conv2d-55          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-56          [-1, 192, 28, 28]             384\n","            ReLU6-57          [-1, 192, 28, 28]               0\n","           Conv2d-58          [-1, 192, 14, 14]           1,728\n","      BatchNorm2d-59          [-1, 192, 14, 14]             384\n","            ReLU6-60          [-1, 192, 14, 14]               0\n","           Conv2d-61           [-1, 64, 14, 14]          12,288\n","      BatchNorm2d-62           [-1, 64, 14, 14]             128\n"," InvertedResidual-63           [-1, 64, 14, 14]               0\n","           Conv2d-64          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-65          [-1, 384, 14, 14]             768\n","            ReLU6-66          [-1, 384, 14, 14]               0\n","           Conv2d-67          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-68          [-1, 384, 14, 14]             768\n","            ReLU6-69          [-1, 384, 14, 14]               0\n","           Conv2d-70           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-71           [-1, 64, 14, 14]             128\n"," InvertedResidual-72           [-1, 64, 14, 14]               0\n","           Conv2d-73          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-74          [-1, 384, 14, 14]             768\n","            ReLU6-75          [-1, 384, 14, 14]               0\n","           Conv2d-76          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-77          [-1, 384, 14, 14]             768\n","            ReLU6-78          [-1, 384, 14, 14]               0\n","           Conv2d-79           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-80           [-1, 64, 14, 14]             128\n"," InvertedResidual-81           [-1, 64, 14, 14]               0\n","           Conv2d-82          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-83          [-1, 384, 14, 14]             768\n","            ReLU6-84          [-1, 384, 14, 14]               0\n","           Conv2d-85          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-86          [-1, 384, 14, 14]             768\n","            ReLU6-87          [-1, 384, 14, 14]               0\n","           Conv2d-88           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-89           [-1, 64, 14, 14]             128\n"," InvertedResidual-90           [-1, 64, 14, 14]               0\n","           Conv2d-91          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-92          [-1, 384, 14, 14]             768\n","            ReLU6-93          [-1, 384, 14, 14]               0\n","           Conv2d-94          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-95          [-1, 384, 14, 14]             768\n","            ReLU6-96          [-1, 384, 14, 14]               0\n","           Conv2d-97           [-1, 96, 14, 14]          36,864\n","      BatchNorm2d-98           [-1, 96, 14, 14]             192\n"," InvertedResidual-99           [-1, 96, 14, 14]               0\n","          Conv2d-100          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n","           ReLU6-102          [-1, 576, 14, 14]               0\n","          Conv2d-103          [-1, 576, 14, 14]           5,184\n","     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n","           ReLU6-105          [-1, 576, 14, 14]               0\n","          Conv2d-106           [-1, 96, 14, 14]          55,296\n","     BatchNorm2d-107           [-1, 96, 14, 14]             192\n","InvertedResidual-108           [-1, 96, 14, 14]               0\n","          Conv2d-109          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n","           ReLU6-111          [-1, 576, 14, 14]               0\n","          Conv2d-112          [-1, 576, 14, 14]           5,184\n","     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n","           ReLU6-114          [-1, 576, 14, 14]               0\n","          Conv2d-115           [-1, 96, 14, 14]          55,296\n","     BatchNorm2d-116           [-1, 96, 14, 14]             192\n","InvertedResidual-117           [-1, 96, 14, 14]               0\n","          Conv2d-118          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n","           ReLU6-120          [-1, 576, 14, 14]               0\n","          Conv2d-121          [-1, 576, 14, 14]           5,184\n","     BatchNorm2d-122          [-1, 576, 14, 14]           1,152\n","           ReLU6-123          [-1, 576, 14, 14]               0\n","          Conv2d-124          [-1, 160, 14, 14]          92,160\n","     BatchNorm2d-125          [-1, 160, 14, 14]             320\n","InvertedResidual-126          [-1, 160, 14, 14]               0\n","          Conv2d-127          [-1, 960, 14, 14]         153,600\n","     BatchNorm2d-128          [-1, 960, 14, 14]           1,920\n","           ReLU6-129          [-1, 960, 14, 14]               0\n","          Conv2d-130          [-1, 960, 14, 14]           8,640\n","     BatchNorm2d-131          [-1, 960, 14, 14]           1,920\n","           ReLU6-132          [-1, 960, 14, 14]               0\n","          Conv2d-133          [-1, 160, 14, 14]         153,600\n","     BatchNorm2d-134          [-1, 160, 14, 14]             320\n","InvertedResidual-135          [-1, 160, 14, 14]               0\n","          Conv2d-136          [-1, 960, 14, 14]         153,600\n","     BatchNorm2d-137          [-1, 960, 14, 14]           1,920\n","           ReLU6-138          [-1, 960, 14, 14]               0\n","          Conv2d-139          [-1, 960, 14, 14]           8,640\n","     BatchNorm2d-140          [-1, 960, 14, 14]           1,920\n","           ReLU6-141          [-1, 960, 14, 14]               0\n","          Conv2d-142          [-1, 160, 14, 14]         153,600\n","     BatchNorm2d-143          [-1, 160, 14, 14]             320\n","InvertedResidual-144          [-1, 160, 14, 14]               0\n","          Conv2d-145          [-1, 960, 14, 14]         153,600\n","     BatchNorm2d-146          [-1, 960, 14, 14]           1,920\n","           ReLU6-147          [-1, 960, 14, 14]               0\n","          Conv2d-148          [-1, 960, 14, 14]           8,640\n","     BatchNorm2d-149          [-1, 960, 14, 14]           1,920\n","           ReLU6-150          [-1, 960, 14, 14]               0\n","          Conv2d-151          [-1, 320, 14, 14]         307,200\n","     BatchNorm2d-152          [-1, 320, 14, 14]             640\n","InvertedResidual-153          [-1, 320, 14, 14]               0\n","          Conv2d-154         [-1, 1280, 14, 14]         409,600\n","     BatchNorm2d-155         [-1, 1280, 14, 14]           2,560\n","           ReLU6-156         [-1, 1280, 14, 14]               0\n","MobileNetV2Encoder-157  [[-1, 3, 224, 224], [-1, 16, 112, 112], [-1, 24, 56, 56], [-1, 32, 28, 28], [-1, 96, 14, 14], [-1, 1280, 14, 14]]               0\n","          Conv2d-158          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-159          [-1, 256, 14, 14]             512\n","            ReLU-160          [-1, 256, 14, 14]               0\n","          Conv2d-161         [-1, 1280, 14, 14]          11,520\n","          Conv2d-162          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-163          [-1, 256, 14, 14]             512\n","            ReLU-164          [-1, 256, 14, 14]               0\n","          Conv2d-165         [-1, 1280, 14, 14]          11,520\n","          Conv2d-166          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-167          [-1, 256, 14, 14]             512\n","            ReLU-168          [-1, 256, 14, 14]               0\n","          Conv2d-169         [-1, 1280, 14, 14]          11,520\n","          Conv2d-170          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-171          [-1, 256, 14, 14]             512\n","            ReLU-172          [-1, 256, 14, 14]               0\n","AdaptiveAvgPool2d-173           [-1, 1280, 1, 1]               0\n","          Conv2d-174            [-1, 256, 1, 1]         327,680\n","     BatchNorm2d-175            [-1, 256, 1, 1]             512\n","            ReLU-176            [-1, 256, 1, 1]               0\n","          Conv2d-177          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-178          [-1, 256, 14, 14]             512\n","            ReLU-179          [-1, 256, 14, 14]               0\n","         Dropout-180          [-1, 256, 14, 14]               0\n","            ASPP-181          [-1, 256, 14, 14]               0\n","          Conv2d-182          [-1, 256, 14, 14]           2,304\n","          Conv2d-183          [-1, 256, 14, 14]          65,536\n","     BatchNorm2d-184          [-1, 256, 14, 14]             512\n","            ReLU-185          [-1, 256, 14, 14]               0\n","UpsamplingBilinear2d-186          [-1, 256, 56, 56]               0\n","          Conv2d-187           [-1, 48, 56, 56]           1,152\n","     BatchNorm2d-188           [-1, 48, 56, 56]              96\n","            ReLU-189           [-1, 48, 56, 56]               0\n","          Conv2d-190          [-1, 304, 56, 56]           2,736\n","          Conv2d-191          [-1, 256, 56, 56]          77,824\n","     BatchNorm2d-192          [-1, 256, 56, 56]             512\n","            ReLU-193          [-1, 256, 56, 56]               0\n","DeepLabV3PlusDecoder-194          [-1, 256, 56, 56]               0\n","          Conv2d-195           [-1, 11, 56, 56]           2,827\n","UpsamplingBilinear2d-196         [-1, 11, 224, 224]               0\n","        Identity-197         [-1, 11, 224, 224]               0\n","      Activation-198         [-1, 11, 224, 224]               0\n","   DeepLabV3Plus-199         [-1, 11, 224, 224]               0\n","================================================================\n","Total params: 4,381,083\n","Trainable params: 2,157,211\n","Non-trainable params: 2,223,872\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 27487790694653.41\n","Params size (MB): 16.71\n","Estimated Total Size (MB): 27487790694670.70\n","----------------------------------------------------------------\n"]}],"source":["from torchsummary import summary\n","summary(model, (3, IMAGE_SIZE, IMAGE_SIZE))"]},{"cell_type":"markdown","metadata":{"id":"cm3Pe4CG6ufa"},"source":["## custom function"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1708136772947,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"YI0PBjxP6xYS"},"outputs":[],"source":["def show_image(image,mask,pred_image = None):\n","\n","    if pred_image == None:\n","\n","        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n","\n","        ax1.set_title('IMAGE')\n","        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')\n","\n","        ax2.set_title('GROUND TRUTH')\n","        grayscale_images = torch.Tensor(np.argmax(mask.numpy(), axis=0) * (255 / (mask.shape[0] - 1)))\n","        ax2.imshow(grayscale_images.permute(0,1).squeeze(),cmap = 'gray')\n","\n","    elif pred_image != None :\n","\n","        f, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(10,5))\n","\n","        ax1.set_title('IMAGE')\n","        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')\n","\n","        ax2.set_title('GROUND TRUTH')\n","        grayscale_images = torch.Tensor(np.argmax(mask.numpy(), axis=0) * (255 / (mask.shape[0] - 1)))\n","        ax2.imshow(grayscale_images.permute(0,1).squeeze(),cmap = 'gray')\n","\n","        ax3.set_title('MODEL OUTPUT')\n","        pred_image = torch.Tensor(np.argmax(pred_image.numpy(), axis=0) * (255 / (pred_image.shape[0] - 1)))\n","        ax3.imshow(pred_image.permute(0,1).squeeze(),cmap = 'gray')"]},{"cell_type":"markdown","metadata":{"id":"So0Ew5uK7xw5"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708136903749,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"U5SDXQAbKAX4","outputId":"5afd0748-a8b8-4cf3-a310-8e805e801590"},"outputs":[{"data":{"text/plain":["SegmentationModel(\n","  (arc): DeepLabV3Plus(\n","    (encoder): MobileNetV2Encoder(\n","      (features): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (4): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (5): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (6): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (7): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (8): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (9): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (10): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (11): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (12): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (13): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (14): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (15): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (16): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (17): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (18): Conv2dNormActivation(\n","          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","      )\n","    )\n","    (decoder): DeepLabV3PlusDecoder(\n","      (aspp): Sequential(\n","        (0): ASPP(\n","          (convs): ModuleList(\n","            (0): Sequential(\n","              (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (1): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (2): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (3): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (4): ASPPPooling(\n","              (0): AdaptiveAvgPool2d(output_size=1)\n","              (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (3): ReLU()\n","            )\n","          )\n","          (project): Sequential(\n","            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU()\n","            (3): Dropout(p=0.5, inplace=False)\n","          )\n","        )\n","        (1): SeparableConv2d(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU()\n","      )\n","      (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (block1): Sequential(\n","        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (block2): Sequential(\n","        (0): SeparableConv2d(\n","          (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n","          (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (segmentation_head): SegmentationHead(\n","      (0): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n","      (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","  )\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()"]},{"cell_type":"markdown","metadata":{"id":"YGa-HilKQGEl"},"source":["class 0 = background\n","\n","class 1 = skin\n","\n","class 2 = left brown\n","\n","class 3 = right brown\n","\n","class 4 = left eye\n","\n","class 5 = right eye\n","\n","class 6 = nose\n","\n","class 7 = upper lip\n","\n","class 8 = mouth\n","\n","class 9 = lower lip\n","\n","class 10 = hair"]},{"cell_type":"markdown","metadata":{"id":"EV6_GCOkEm0Y"},"source":["## Download shape_predictor"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":705,"status":"ok","timestamp":1708136910954,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"VXmIRa_bErqp"},"outputs":[],"source":["import dlib"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12828,"status":"ok","timestamp":1708136923778,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"YjVWAyuXEuaE","outputId":"2db76b2f-bb55-4b86-b773-ff223caa9555"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-02-17 02:28:29--  https://github.com/italojs/facial-landmarks-recognition/archive/refs/heads/master.zip\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://codeload.github.com/italojs/facial-landmarks-recognition/zip/refs/heads/master [following]\n","--2024-02-17 02:28:30--  https://codeload.github.com/italojs/facial-landmarks-recognition/zip/refs/heads/master\n","Resolving codeload.github.com (codeload.github.com)... 20.27.177.114\n","Connecting to codeload.github.com (codeload.github.com)|20.27.177.114|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘shape’\n","\n","shape                   [             \u003c=\u003e    ]  68.98M  24.3MB/s    in 2.8s    \n","\n","2024-02-17 02:28:42 (24.3 MB/s) - ‘shape’ saved [72327196]\n","\n"]}],"source":["!wget https://github.com/italojs/facial-landmarks-recognition/archive/refs/heads/master.zip -O 'shape'"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":716,"status":"ok","timestamp":1708136924489,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"q2Bpae5QFMKp","outputId":"2630b309-d1ab-476b-8a49-9cb6aba50ef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  shape\n","d37b6a7426e98094e28fa99254e270a3e9b6d591\n","   creating: shape_pred/facial-landmarks-recognition-master/\n","  inflating: shape_pred/facial-landmarks-recognition-master/README.md  \n","  inflating: shape_pred/facial-landmarks-recognition-master/main.py  \n","  inflating: shape_pred/facial-landmarks-recognition-master/shape_predictor_68_face_landmarks.dat  \n"]}],"source":["!unzip 'shape' -d 'shape_pred'"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":1111,"status":"ok","timestamp":1708136925599,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"P7h324VJFVyx"},"outputs":[],"source":["predictor_path = '/content/shape_pred/facial-landmarks-recognition-master/shape_predictor_68_face_landmarks.dat'"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708136926538,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"ypJ82JxoFYq5"},"outputs":[],"source":["detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(predictor_path)"]},{"cell_type":"markdown","metadata":{"id":"XJ6HkpqpGDTZ"},"source":["## Function"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":510,"status":"ok","timestamp":1708137164355,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"W0c23z77GEjq"},"outputs":[],"source":["total = list(range(0,68))\n","left_eye_indices = list(range(36, 42))\n","right_eye_indices = list(range(42, 48))\n","mouth_indices = list(range(48, 61))\n","smile_indices = list(range(48, 68))\n","\n","#PARAM\n","#use BGR which is blue / green / red\n","left_eye_color = [125,125,0]\n","#use BGR which is blue / green / red\n","right_eye_color = [0,125,125]\n","#use HSV which is hue value\n","mouth_h = 300\n","\n","#change/swap part of image\n","def add_part_image(full_img,part,mask):\n","    mask_inv = cv2.bitwise_not(mask)\n","    background = cv2.bitwise_and(full_img,full_img,mask = mask_inv)\n","    result = cv2.add(background,part)\n","    return result\n","\n","#change mouth color base on mask\n","def change_mouth_color(bgr_img,mask,hue,logit_mouth,CURRENT_FACIAL):\n","    hsv_img = cv2.cvtColor(bgr_img,cv2.COLOR_BGR2HSV)\n","    my_mask = None\n","    if mask is not None:\n","        _,thresh = cv2.threshold(mask, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","        if (CURRENT_FACIAL is not None):\n","            CURRENT_FACIAL = cv2.bitwise_or(CURRENT_FACIAL,thresh)\n","        my_mask = cv2.bitwise_or(logit_mouth,mask)\n","    else:\n","        my_mask = logit_mouth\n","    h, s, v = cv2.split(hsv_img)\n","    h[my_mask == 255] = hue\n","    hsv_img = cv2.merge([h,s,v])\n","\n","    img = cv2.cvtColor(hsv_img,cv2.COLOR_HSV2BGR)\n","    return img , CURRENT_FACIAL\n","\n","#change iris eye base on mask\n","def change_iris_eye(bgr_img,mask,color,CURRENT_FACIAL):\n","    gray = cv2.cvtColor(bgr_img,cv2.COLOR_BGR2GRAY)\n","    gray = cv2.bitwise_and(gray,gray,mask = mask)\n","   # eye = cv2.bitwise_and(gray,gray,mask = mask)\n","    _,thresh = cv2.threshold(gray, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","    thresh = cv2.bitwise_and(thresh,thresh,mask = mask)\n","\n","    iris = bgr_img.copy()\n","    iris[:,:] = color\n","\n","    iris = cv2.bitwise_and(iris,iris,mask = thresh)\n","    if (CURRENT_FACIAL is not  None):\n","        CURRENT_FACIAL = cv2.add(CURRENT_FACIAL,thresh)\n","    #iris = cv2.bitwise_and(iris,iris,mask = mask)\n","\n","    result = add_part_image(bgr_img,iris,thresh)\n","    return result , CURRENT_FACIAL\n","\n","#get face mask\n","def get_face(gray,landmarks):\n","    mask = np.zeros_like(gray)\n","    points = np.array([(landmarks.part(n).x,landmarks.part(n).y) for n in total])\n","    hull = cv2.convexHull(points)\n","    cv2.fillConvexPoly(mask, hull,255)\n","    return mask\n","\n","#enhance face with mask\n","def enhance_face(hsv_img,result,mask):\n","    face_region = cv2.bitwise_and(hsv_img,hsv_img, mask = mask)\n","    face_region[:,:,2] = cv2.equalizeHist(face_region[:,:,2])\n","    face_region = cv2.cvtColor(face_region,cv2.COLOR_HSV2BGR)\n","    result = add_part_image(result,face_region,mask)\n","    return result\n","\n","#get mouth mask\n","def get_mouth(logit,WIDTH,HEIGHT):\n","    mouth0 = (logit.numpy().astype(np.uint8))[7,:,:]\n","    mouth1 = (logit.numpy().astype(np.uint8))[8,:,:]\n","    mouth2 = (logit.numpy().astype(np.uint8))[9,:,:]\n","\n","    _, mouth0 =  cv2.threshold(mouth0, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","    _, mouth1 =  cv2.threshold(mouth1, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","    _, mouth2 =  cv2.threshold(mouth2, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","\n","    mouth = mouth0\n","    mouth = cv2.bitwise_or(mouth,mouth1)\n","    mouth = cv2.bitwise_or(mouth,mouth2)\n","\n","    kernel = np.ones((5,5),np.uint8)\n","    mouth = cv2.morphologyEx(mouth,cv2.MORPH_OPEN,kernel,iterations = 1)\n","    mouth = cv2.resize(mouth,(WIDTH,HEIGHT))\n","\n","    return mouth\n","\n","\n","# combination of function to enhancement\n","def main(detector,predictor,frame,logit,logit_mouth,CURRENT_FACIAL,CURRENT_FACE):\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    faces = detector(gray)\n","    result = frame.copy()\n","    hsv_img = cv2.cvtColor(result,cv2.COLOR_BGR2HSV)\n","    B,G,R = cv2.split(result)\n","    laplacian = np.array([\n","        [0,-1,0],\n","        [-1,5,-1],\n","        [0,-1,0]\n","    ])\n","    blur_kernel = (5,5)\n","    B = cv2.GaussianBlur(B,blur_kernel,0)\n","    G = cv2.GaussianBlur(G,blur_kernel,0)\n","    R = cv2.GaussianBlur(R,blur_kernel,0)\n","\n","    R = cv2.medianBlur(R,3)\n","    G = cv2.medianBlur(G,3)\n","    B = cv2.medianBlur(B,3)\n","\n","    B = cv2.filter2D(B.astype(np.int16),-1,laplacian).clip(0,255).astype(np.uint8)\n","    G = cv2.filter2D(G.astype(np.int16),-1,laplacian).clip(0,255).astype(np.uint8)\n","    R = cv2.filter2D(R.astype(np.int16),-1,laplacian).clip(0,255).astype(np.uint8)\n","    result = cv2.merge([B,G,R])\n","    for face in faces:\n","        landmarks = predictor(gray, face)\n","        mask = get_face(gray,landmarks)\n","        if (CURRENT_FACE is not None):\n","            CURRENT_FACE = cv2.bitwise_or(CURRENT_FACE,mask)\n","        result = enhance_face(hsv_img,result,cv2.bitwise_or(mask,logit))\n","        left_eye = np.array([((landmarks.part(idx).x) , (landmarks.part(idx).y)) for idx in left_eye_indices])\n","        right_eye = np.array([((landmarks.part(idx).x) , (landmarks.part(idx).y)) for idx in right_eye_indices])\n","        mouth = np.array([((landmarks.part(idx).x) , (landmarks.part(idx).y)) for idx in mouth_indices])\n","        mask1 = np.zeros(frame.shape[:2],dtype=np.uint8)\n","        mask2 = np.zeros(frame.shape[:2],dtype=np.uint8)\n","        mask3 = np.zeros(frame.shape[:2],dtype=np.uint8)\n","        cv2.drawContours(mask1,[left_eye],-1, (255, 255, 255), -1, cv2.LINE_AA)\n","        cv2.drawContours(mask2,[right_eye],-1, (255, 255, 255), -1, cv2.LINE_AA)\n","        cv2.drawContours(mask3,[mouth],-1, (255, 255, 255), -1, cv2.LINE_AA)\n","\n","        result , CURRENT_FACIAL = change_mouth_color(result,mask3,mouth_h,logit_mouth,CURRENT_FACIAL)\n","        result , CURRENT_FACIAL = change_iris_eye(result,mask1,left_eye_color,CURRENT_FACIAL)\n","        result , CURRENT_FACIAL = change_iris_eye(result,mask2,right_eye_color,CURRENT_FACIAL)\n","    if (len(faces) == 0):\n","        result = enhance_face(hsv_img,result,logit)\n","        result , CURRENT_FACIAL = change_mouth_color(result,None,mouth_h,logit_mouth,CURRENT_FACIAL)\n","    return result , CURRENT_FACIAL , CURRENT_FACE\n","\n","#\n","def enhancer(image):\n","    HEIGHT,WIDTH = image.shape[:2]\n","\n","\n","    #initial combine result mask from method\n","    # get mask from model\n","    my_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    my_img = cv2.resize(my_img,(224,224))\n","    my_img = np.transpose(my_img, (2,0,1)).astype(np.float32)\n","    my_img = torch.Tensor(my_img) / 255.0\n","    logit = model(my_img.to(DEVICE).unsqueeze(0))\n","    my_logit = logit.detach().cpu().squeeze(0)\n","    my_logit = torch.sigmoid(my_logit)\n","    my_logit = (my_logit \u003e 0.5) * 255.0\n","\n","    #get face\n","    mouth = get_mouth(my_logit,WIDTH,HEIGHT)\n","    nhair = (my_logit.numpy().astype(np.uint8))[10,:,:]\n","    face = (my_logit.numpy().astype(np.uint8))[0,:,:]\n","    _, nhair =  cv2.threshold(nhair, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","    _, face =  cv2.threshold(face, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","    mask_face = cv2.bitwise_and(nhair,face)\n","    kernel = np.ones((5,5),np.uint8)\n","    #remove noise\n","    mask_face = cv2.morphologyEx(mask_face,cv2.MORPH_OPEN,kernel,iterations = 1)\n","    mask_face = cv2.resize(mask_face,(WIDTH,HEIGHT))\n","    # result = main(detector,predictor,image)(detector,predictor,frame,logit,logit_mouth,CURRENT_FACIAL,CURRENT_FACE)\n","    result , CURRENT_FACIAL , CURRENT_FACE = main(detector,predictor,image,mask_face,mouth,None, None)\n","    result = cv2.cvtColor(result,cv2.COLOR_BGR2RGB)\n","\n","    return result"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708136926539,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"-vl3KAHNpDG6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"BtaEWt9gEd2z"},"source":["## Use Case"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708136926539,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"r-Qe3LnLSf2q"},"outputs":[],"source":["def my_iou(predict,mask):\n","    predict = predict // 255\n","    mask = mask // 255\n","    intersection = np.sum(predict \u0026 mask)\n","    union = np.sum(predict | mask)\n","    return (intersection + 1e-10) / (union + 1e-10)"]},{"cell_type":"markdown","metadata":{"id":"3UvtZZblM_Y-"},"source":["### Eval"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1DTn-ifdQDJdigaSdJPobAb2WT79WExSR"},"executionInfo":{"elapsed":173789,"status":"ok","timestamp":1708137100325,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"ZV9vnzYHEfl8","outputId":"0d13b741-d9b0-47b5-d2ba-c034b576c9bd"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["path_img = '/content/archive'\n","path_markup = '/content/markup'\n","path_face_m = '/content/face-m'\n","score = np.zeros(100,dtype = np.float64)\n","fscore = np.zeros(100,dtype = np.float64)\n","psnr = np.zeros(100,dtype = np.float64)\n","c = 10\n","K = 0.0001\n","model.eval()\n","with torch.no_grad():\n","    for i in range(0,100):\n","        p = os.path.join(path_img,f'1 ({i + 1}).jpg')\n","        image = cv2.imread(p)\n","        HEIGHT,WIDTH = image.shape[:2]\n","        my_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        my_img = cv2.resize(my_img,(224,224))\n","        my_img = np.transpose(my_img, (2,0,1)).astype(np.float32)\n","        my_img = torch.Tensor(my_img) / 255.0\n","        logit = model(my_img.to(DEVICE).unsqueeze(0))\n","\n","        CURRENT_FACIAL = np.zeros((HEIGHT,WIDTH),dtype = np.uint8)\n","        CURRENT_FACE = np.zeros((HEIGHT,WIDTH),dtype = np.uint8)\n","\n","        my_logit = logit.detach().cpu().squeeze(0)\n","        my_logit = torch.sigmoid(my_logit)\n","        my_logit = (my_logit \u003e 0.5) * 255.0\n","\n","        mouth = get_mouth(my_logit,WIDTH,HEIGHT)\n","        # get hair -\u003e inv -\u003e get all area that doesn't include hair\n","        nhair = (my_logit.numpy().astype(np.uint8))[10,:,:]\n","        # background -\u003e inv -\u003e get all area that not background(head of person)\n","        # when two mask use and bitwise will got all face that don't include hair\n","        face = (my_logit.numpy().astype(np.uint8))[0,:,:]\n","        # not hair will get\n","        _, nhair =  cv2.threshold(nhair, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","        # not background will get head area for all\n","        _, face =  cv2.threshold(face, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","        mask_face = cv2.bitwise_and(nhair,face)\n","        kernel = np.ones((5,5),np.uint8)\n","        mask_face = cv2.morphologyEx(mask_face,cv2.MORPH_OPEN,kernel,iterations = 1)\n","        mask_face = cv2.resize(mask_face,(WIDTH,HEIGHT))\n","\n","        p_markup = os.path.join(path_markup,f'1 ({i + 1}).jpg')\n","        markup = cv2.imread(p_markup,0)\n","        _, thresh =  cv2.threshold(markup, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","\n","        f_markup = os.path.join(path_face_m,f'1 ({i + 1}).jpg')\n","        fmarkup = cv2.imread(f_markup,0)\n","        _, fthresh =  cv2.threshold(fmarkup, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","        CURRENT_FACE = mask_face\n","        CURRENT_FACIAL = mouth\n","    # result = main(detector,predictor,image)\n","        result , CURRENT_FACIAL , CURRENT_FACE = main(detector,predictor,image,mask_face,mouth,CURRENT_FACIAL, CURRENT_FACE)\n","        result = cv2.cvtColor(result,cv2.COLOR_BGR2RGB)\n","        score[i] = my_iou(CURRENT_FACIAL,thresh)\n","        fscore[i] = my_iou(CURRENT_FACE,fthresh)\n","        original = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        print(f'facial enhance = {score[i]} , face enhance = { fscore[i]}')\n","        plt.figure(figsize=(14,6))\n","        plt.subplot(1,6,1)\n","        plt.imshow(original)\n","        plt.subplot(1,6,2)\n","        plt.imshow(result)\n","        plt.subplot(1,6,3)\n","        plt.imshow(CURRENT_FACIAL,cmap = 'gray')\n","        plt.subplot(1,6,4)\n","        plt.imshow(thresh, cmap = 'gray')\n","        plt.subplot(1,6,5)\n","        plt.imshow(CURRENT_FACE,cmap = 'gray')\n","        plt.subplot(1,6,6)\n","        plt.imshow(fthresh,cmap = 'gray')\n","        plt.show()\n","    print(f'average iou = {np.mean(fscore)}')\n","    print(f'average iou = {np.mean(score)}')"]},{"cell_type":"markdown","metadata":{"id":"PUXcur7lNAhH"},"source":["### Use function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":615,"output_embedded_package_id":"1euN9V8WsvPwx3_BCZZSOqwCvKtEr7Iim"},"id":"SPbCJir6QheA","outputId":"fc24acaa-37b9-40a2-8860-5fec534526f2"},"outputs":[],"source":["import random\n","path_img = '/content/archive'\n","path_markup = '/content/markup'\n","path_face_m = '/content/face-m'\n","c = 10\n","K = 0.0001\n","model.eval()\n","with torch.no_grad():\n","    for i in random.sample(range(0,100),5):\n","        p = os.path.join(path_img,f'1 ({i + 1}).jpg')\n","        image = cv2.imread(p)\n","        result = enhancer(image)\n","\n","        original = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        plt.figure(figsize=(14,6))\n","        plt.subplot(1,2,1)\n","        plt.imshow(original)\n","        plt.subplot(1,2,2)\n","        plt.imshow(result)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1708136772948,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"},"user_tz":-420},"id":"NxKkGRNIuEH6"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPkeuYo6cx/4SxdLaNZTXdB","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}