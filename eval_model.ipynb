{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOgqT5ZqnucGka6WWflphqk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BO6l4Xl70DME","executionInfo":{"status":"ok","timestamp":1708613054167,"user_tz":-420,"elapsed":41840,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"725048cf-1016-4341-96d1-df04093795cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m102.4/106.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.16.0+cu121)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=629a77ed90bb4690621db5518aa15536cfee6a65d38bcc79c7b76b26af0a4c49\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=dc47663c54b9e577f00bcf47968c26023ae378c299f9c8f6df722eda4e3cc61e\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n","Collecting git+https://github.com/albumentations-team/albumentations\n","  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-9uh5pm2h\n","  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations /tmp/pip-req-build-9uh5pm2h\n","  Resolved https://github.com/albumentations-team/albumentations to commit 0d4cb9608cdc27fc77256c53c132379816132a32\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (1.25.2)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (1.11.4)\n","Collecting scikit-image>=0.21.0 (from albumentations==1.4.0)\n","  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (6.0.1)\n","Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (0.0.4)\n","Requirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (4.9.0.80)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.4.0) (1.2.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.4.0) (4.9.0)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (3.2.1)\n","Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (9.4.0)\n","Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (2.31.6)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (2024.2.12)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (23.2)\n","Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (0.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.4.0) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.4.0) (3.3.0)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-1.4.0-py3-none-any.whl size=124883 sha256=9b77ea2a7cd1f3d5756413ee36f39a0c84505609c67332af1cb95be74f574c4d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vugygp6_/wheels/51/4d/ab/5aafa8b980086fbc362946de7da4aa3df33aacb3da0da29b93\n","Successfully built albumentations\n","Installing collected packages: scikit-image, albumentations\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.3.1\n","    Uninstalling albumentations-1.3.1:\n","      Successfully uninstalled albumentations-1.3.1\n","Successfully installed albumentations-1.4.0 scikit-image-0.22.0\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Collecting opencv-contrib-python\n","  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.25.2)\n","Installing collected packages: opencv-contrib-python\n","  Attempting uninstall: opencv-contrib-python\n","    Found existing installation: opencv-contrib-python 4.8.0.76\n","    Uninstalling opencv-contrib-python-4.8.0.76:\n","      Successfully uninstalled opencv-contrib-python-4.8.0.76\n","Successfully installed opencv-contrib-python-4.9.0.80\n","--2024-02-22 14:44:12--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2813 (2.7K) [text/plain]\n","Saving to: ‘helper.py’\n","\n","helper.py           100%[===================>]   2.75K  --.-KB/s    in 0s      \n","\n","2024-02-22 14:44:12 (49.8 MB/s) - ‘helper.py’ saved [2813/2813]\n","\n","--2024-02-22 14:44:12--  https://docs.google.com/uc?export=download&confirm=&id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG\n","Resolving docs.google.com (docs.google.com)... 173.194.215.139, 173.194.215.100, 173.194.215.113, ...\n","Connecting to docs.google.com (docs.google.com)|173.194.215.139|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG&export=download [following]\n","--2024-02-22 14:44:12--  https://drive.usercontent.google.com/download?id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG&export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.213.132, 2607:f8b0:400c:c0a::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.213.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2423 (2.4K) [text/html]\n","Saving to: ‘tmp’\n","\n","tmp                 100%[===================>]   2.37K  --.-KB/s    in 0s      \n","\n","2024-02-22 14:44:13 (37.4 MB/s) - ‘tmp’ saved [2423/2423]\n","\n"]}],"source":["!pip install segmentation-models-pytorch\n","!pip install -U git+https://github.com/albumentations-team/albumentations\n","!pip install --upgrade opencv-contrib-python\n","!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1XOBoRGSraP50_pS1YPB8_i8Wmw_5L-NG\" -O 'tmp' && rm -rf /tmp/cookies.txt"]},{"cell_type":"code","source":["import torch\n","import cv2\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import helper\n","\n","from torch.utils.data import Dataset\n","import os\n","import numpy as np\n","from glob import glob\n","import tensorflow as tf\n","from torch.utils.data import DataLoader\n","from torch import nn\n","import segmentation_models_pytorch as smp\n","from torch.nn.functional import one_hot\n","from segmentation_models_pytorch.losses import DiceLoss"],"metadata":{"id":"Eeh1TTKP07d_","executionInfo":{"status":"ok","timestamp":1708613203315,"user_tz":-420,"elapsed":389,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HbGrvBUMYDVf","executionInfo":{"status":"ok","timestamp":1708613067506,"user_tz":-420,"elapsed":5,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoTOfFtRYDCr","executionInfo":{"status":"ok","timestamp":1708613128679,"user_tz":-420,"elapsed":61177,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"7cff3788-489a-4bb9-a59a-9dab597aec99"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["if not os.path.exists('image'):\n","    os.makedirs('image')"],"metadata":{"id":"-RqWKzrG0rXf","executionInfo":{"status":"ok","timestamp":1708613128679,"user_tz":-420,"elapsed":11,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!tar -xvf  '/content/tmp' -C '/content/image'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ow9ID4J0h4A","executionInfo":{"status":"ok","timestamp":1708613128679,"user_tz":-420,"elapsed":9,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"7eadf0cc-a288-4863-fc0e-4454093445c7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tar: This does not look like a tar archive\n","tar: Skipping to next header\n","tar: Exiting with failure status due to previous errors\n"]}]},{"cell_type":"markdown","source":["## Download file testing enhanment"],"metadata":{"id":"swdW2xj815rW"}},{"cell_type":"code","source":["!wget \"https://drive.google.com/uc?export=download&id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V\" -O \"test-im\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l97Y1g3y1962","executionInfo":{"status":"ok","timestamp":1708613131720,"user_tz":-420,"elapsed":3047,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"67557a3d-c9bb-4e08-aa53-447cfe0696fa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-22 14:45:27--  https://drive.google.com/uc?export=download&id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V\n","Resolving drive.google.com (drive.google.com)... 74.125.26.100, 74.125.26.138, 74.125.26.102, ...\n","Connecting to drive.google.com (drive.google.com)|74.125.26.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V&export=download [following]\n","--2024-02-22 14:45:27--  https://drive.usercontent.google.com/download?id=1WeP0mTjUDBt2Zx4JWO0U0xf15jwpsr6V&export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.213.132, 2607:f8b0:400c:c0a::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.213.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 21318708 (20M) [application/octet-stream]\n","Saving to: ‘test-im’\n","\n","test-im             100%[===================>]  20.33M  76.0MB/s    in 0.3s    \n","\n","2024-02-22 14:45:30 (76.0 MB/s) - ‘test-im’ saved [21318708/21318708]\n","\n"]}]},{"cell_type":"code","source":["!cp \"gdrive/MyDrive/test_file.zip\" \"test-im\""],"metadata":{"id":"4Q3G-MvOPMyT","executionInfo":{"status":"ok","timestamp":1708613132376,"user_tz":-420,"elapsed":659,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!unzip 'test-im' -d 'archive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pm2bKDlj3YjX","executionInfo":{"status":"ok","timestamp":1708613132811,"user_tz":-420,"elapsed":437,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"75b92dec-3daa-44ed-ce1b-32c06463ae8e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  test-im\n","  inflating: archive/1 (1).jpg       \n","  inflating: archive/1 (10).jpg      \n","  inflating: archive/1 (100).jpg     \n","  inflating: archive/1 (11).jpg      \n","  inflating: archive/1 (12).jpg      \n","  inflating: archive/1 (13).jpg      \n","  inflating: archive/1 (14).jpg      \n","  inflating: archive/1 (15).jpg      \n","  inflating: archive/1 (16).jpg      \n","  inflating: archive/1 (17).jpg      \n","  inflating: archive/1 (18).jpg      \n","  inflating: archive/1 (19).jpg      \n","  inflating: archive/1 (2).jpg       \n","  inflating: archive/1 (20).jpg      \n","  inflating: archive/1 (21).jpg      \n","  inflating: archive/1 (22).jpg      \n","  inflating: archive/1 (23).jpg      \n","  inflating: archive/1 (24).jpg      \n","  inflating: archive/1 (25).jpg      \n","  inflating: archive/1 (26).jpg      \n","  inflating: archive/1 (27).jpg      \n","  inflating: archive/1 (28).jpg      \n","  inflating: archive/1 (29).jpg      \n","  inflating: archive/1 (3).jpg       \n","  inflating: archive/1 (30).jpg      \n","  inflating: archive/1 (31).jpg      \n","  inflating: archive/1 (32).jpg      \n","  inflating: archive/1 (33).jpg      \n","  inflating: archive/1 (34).jpg      \n","  inflating: archive/1 (35).jpg      \n","  inflating: archive/1 (36).jpg      \n","  inflating: archive/1 (37).jpg      \n","  inflating: archive/1 (38).jpg      \n","  inflating: archive/1 (39).jpg      \n","  inflating: archive/1 (4).jpg       \n","  inflating: archive/1 (40).jpg      \n","  inflating: archive/1 (41).jpg      \n","  inflating: archive/1 (42).jpg      \n","  inflating: archive/1 (43).jpg      \n","  inflating: archive/1 (44).jpg      \n","  inflating: archive/1 (45).jpg      \n","  inflating: archive/1 (46).jpg      \n","  inflating: archive/1 (47).jpg      \n","  inflating: archive/1 (48).jpg      \n","  inflating: archive/1 (49).jpg      \n","  inflating: archive/1 (5).jpg       \n","  inflating: archive/1 (50).jpg      \n","  inflating: archive/1 (51).jpg      \n","  inflating: archive/1 (52).jpg      \n","  inflating: archive/1 (53).jpg      \n","  inflating: archive/1 (54).jpg      \n","  inflating: archive/1 (55).jpg      \n","  inflating: archive/1 (56).jpg      \n","  inflating: archive/1 (57).jpg      \n","  inflating: archive/1 (58).jpg      \n","  inflating: archive/1 (59).jpg      \n","  inflating: archive/1 (6).jpg       \n","  inflating: archive/1 (60).jpg      \n","  inflating: archive/1 (61).jpg      \n","  inflating: archive/1 (62).jpg      \n","  inflating: archive/1 (63).jpg      \n","  inflating: archive/1 (64).jpg      \n","  inflating: archive/1 (65).jpg      \n","  inflating: archive/1 (66).jpg      \n","  inflating: archive/1 (67).jpg      \n","  inflating: archive/1 (68).jpg      \n","  inflating: archive/1 (69).jpg      \n","  inflating: archive/1 (7).jpg       \n","  inflating: archive/1 (70).jpg      \n","  inflating: archive/1 (71).jpg      \n","  inflating: archive/1 (72).jpg      \n","  inflating: archive/1 (73).jpg      \n","  inflating: archive/1 (74).jpg      \n","  inflating: archive/1 (75).jpg      \n","  inflating: archive/1 (76).jpg      \n","  inflating: archive/1 (77).jpg      \n","  inflating: archive/1 (78).jpg      \n","  inflating: archive/1 (79).jpg      \n","  inflating: archive/1 (8).jpg       \n","  inflating: archive/1 (80).jpg      \n","  inflating: archive/1 (81).jpg      \n","  inflating: archive/1 (82).jpg      \n","  inflating: archive/1 (83).jpg      \n","  inflating: archive/1 (84).jpg      \n","  inflating: archive/1 (85).jpg      \n","  inflating: archive/1 (86).jpg      \n","  inflating: archive/1 (87).jpg      \n","  inflating: archive/1 (88).jpg      \n","  inflating: archive/1 (89).jpg      \n","  inflating: archive/1 (9).jpg       \n","  inflating: archive/1 (90).jpg      \n","  inflating: archive/1 (91).jpg      \n","  inflating: archive/1 (92).jpg      \n","  inflating: archive/1 (93).jpg      \n","  inflating: archive/1 (94).jpg      \n","  inflating: archive/1 (95).jpg      \n","  inflating: archive/1 (96).jpg      \n","  inflating: archive/1 (97).jpg      \n","  inflating: archive/1 (98).jpg      \n","  inflating: archive/1 (99).jpg      \n"]}]},{"cell_type":"code","source":["!wget 'https://drive.google.com/uc?export=download&id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG' -O \"test-mark\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q599bDvnD39F","executionInfo":{"status":"ok","timestamp":1708613134236,"user_tz":-420,"elapsed":1432,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"5269fa12-cb28-48f5-f3aa-4917afc76d58"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-22 14:45:31--  https://drive.google.com/uc?export=download&id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG\n","Resolving drive.google.com (drive.google.com)... 74.125.26.100, 74.125.26.138, 74.125.26.102, ...\n","Connecting to drive.google.com (drive.google.com)|74.125.26.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG&export=download [following]\n","--2024-02-22 14:45:31--  https://drive.usercontent.google.com/download?id=1-sr6XByGYKRdIDuS3MjAWCBnhX1_OnGG&export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.213.132, 2607:f8b0:400c:c0a::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.213.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 387773 (379K) [application/octet-stream]\n","Saving to: ‘test-mark’\n","\n","test-mark           100%[===================>] 378.68K  --.-KB/s    in 0.006s  \n","\n","2024-02-22 14:45:32 (60.9 MB/s) - ‘test-mark’ saved [387773/387773]\n","\n"]}]},{"cell_type":"code","source":["!cp \"gdrive/MyDrive/test-markup.zip\" \"test-mark\""],"metadata":{"id":"HxBmWIl9PY0m","executionInfo":{"status":"ok","timestamp":1708613134236,"user_tz":-420,"elapsed":3,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!unzip \"test-mark\" -d \"markup\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkTwNWpUEFyE","executionInfo":{"status":"ok","timestamp":1708613134656,"user_tz":-420,"elapsed":422,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"2bcb8a9c-4403-4c46-a3ca-8dda9e942dda"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  test-mark\n","  inflating: markup/1 (1).jpg        \n","  inflating: markup/1 (10).jpg       \n","  inflating: markup/1 (100).jpg      \n","  inflating: markup/1 (11).jpg       \n","  inflating: markup/1 (12).jpg       \n","  inflating: markup/1 (13).jpg       \n","  inflating: markup/1 (14).jpg       \n","  inflating: markup/1 (15).jpg       \n","  inflating: markup/1 (16).jpg       \n","  inflating: markup/1 (17).jpg       \n","  inflating: markup/1 (18).jpg       \n","  inflating: markup/1 (19).jpg       \n","  inflating: markup/1 (2).jpg        \n","  inflating: markup/1 (20).jpg       \n","  inflating: markup/1 (21).jpg       \n","  inflating: markup/1 (22).jpg       \n","  inflating: markup/1 (23).jpg       \n","  inflating: markup/1 (24).jpg       \n","  inflating: markup/1 (25).jpg       \n","  inflating: markup/1 (26).jpg       \n","  inflating: markup/1 (27).jpg       \n","  inflating: markup/1 (28).jpg       \n","  inflating: markup/1 (29).jpg       \n","  inflating: markup/1 (3).jpg        \n","  inflating: markup/1 (30).jpg       \n","  inflating: markup/1 (31).jpg       \n","  inflating: markup/1 (32).jpg       \n","  inflating: markup/1 (33).jpg       \n","  inflating: markup/1 (34).jpg       \n","  inflating: markup/1 (35).jpg       \n","  inflating: markup/1 (36).jpg       \n","  inflating: markup/1 (37).jpg       \n","  inflating: markup/1 (38).jpg       \n","  inflating: markup/1 (39).jpg       \n","  inflating: markup/1 (4).jpg        \n","  inflating: markup/1 (40).jpg       \n","  inflating: markup/1 (41).jpg       \n","  inflating: markup/1 (42).jpg       \n","  inflating: markup/1 (43).jpg       \n","  inflating: markup/1 (44).jpg       \n","  inflating: markup/1 (45).jpg       \n","  inflating: markup/1 (46).jpg       \n","  inflating: markup/1 (47).jpg       \n","  inflating: markup/1 (48).jpg       \n","  inflating: markup/1 (49).jpg       \n","  inflating: markup/1 (5).jpg        \n","  inflating: markup/1 (50).jpg       \n","  inflating: markup/1 (51).jpg       \n","  inflating: markup/1 (52).jpg       \n","  inflating: markup/1 (53).jpg       \n","  inflating: markup/1 (54).jpg       \n","  inflating: markup/1 (55).jpg       \n","  inflating: markup/1 (56).jpg       \n","  inflating: markup/1 (57).jpg       \n","  inflating: markup/1 (58).jpg       \n","  inflating: markup/1 (59).jpg       \n","  inflating: markup/1 (6).jpg        \n","  inflating: markup/1 (60).jpg       \n","  inflating: markup/1 (61).jpg       \n","  inflating: markup/1 (62).jpg       \n","  inflating: markup/1 (63).jpg       \n","  inflating: markup/1 (64).jpg       \n","  inflating: markup/1 (65).jpg       \n","  inflating: markup/1 (66).jpg       \n","  inflating: markup/1 (67).jpg       \n","  inflating: markup/1 (68).jpg       \n","  inflating: markup/1 (69).jpg       \n","  inflating: markup/1 (7).jpg        \n","  inflating: markup/1 (70).jpg       \n","  inflating: markup/1 (71).jpg       \n","  inflating: markup/1 (72).jpg       \n","  inflating: markup/1 (73).jpg       \n","  inflating: markup/1 (74).jpg       \n","  inflating: markup/1 (75).jpg       \n","  inflating: markup/1 (76).jpg       \n","  inflating: markup/1 (77).jpg       \n","  inflating: markup/1 (78).jpg       \n","  inflating: markup/1 (79).jpg       \n","  inflating: markup/1 (8).jpg        \n","  inflating: markup/1 (80).jpg       \n","  inflating: markup/1 (81).jpg       \n","  inflating: markup/1 (82).jpg       \n","  inflating: markup/1 (83).jpg       \n","  inflating: markup/1 (84).jpg       \n","  inflating: markup/1 (85).jpg       \n","  inflating: markup/1 (86).jpg       \n","  inflating: markup/1 (87).jpg       \n","  inflating: markup/1 (88).jpg       \n","  inflating: markup/1 (89).jpg       \n","  inflating: markup/1 (9).jpg        \n","  inflating: markup/1 (90).jpg       \n","  inflating: markup/1 (91).jpg       \n","  inflating: markup/1 (92).jpg       \n","  inflating: markup/1 (93).jpg       \n","  inflating: markup/1 (94).jpg       \n","  inflating: markup/1 (95).jpg       \n","  inflating: markup/1 (96).jpg       \n","  inflating: markup/1 (97).jpg       \n","  inflating: markup/1 (98).jpg       \n","  inflating: markup/1 (99).jpg       \n"]}]},{"cell_type":"code","source":["!wget \"https://drive.google.com/uc?export=download&id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx\" -O \"face-mark\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sJahuhiu-M9","executionInfo":{"status":"ok","timestamp":1708613136222,"user_tz":-420,"elapsed":1571,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"a5564473-c803-40d9-edb1-bea8d2922ee5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-22 14:45:33--  https://drive.google.com/uc?export=download&id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx\n","Resolving drive.google.com (drive.google.com)... 74.125.26.100, 74.125.26.138, 74.125.26.102, ...\n","Connecting to drive.google.com (drive.google.com)|74.125.26.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx&export=download [following]\n","--2024-02-22 14:45:33--  https://drive.usercontent.google.com/download?id=1K0QTK_GSyai5vNwMgaO3Kh54n5w4Sjtx&export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.213.132, 2607:f8b0:400c:c0a::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.213.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1109365 (1.1M) [application/octet-stream]\n","Saving to: ‘face-mark’\n","\n","face-mark           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n","\n","2024-02-22 14:45:35 (102 MB/s) - ‘face-mark’ saved [1109365/1109365]\n","\n"]}]},{"cell_type":"code","source":["!cp \"gdrive/MyDrive/face_marker.zip\" \"face-mark\""],"metadata":{"id":"jTsPGGpaPj8u","executionInfo":{"status":"ok","timestamp":1708613137013,"user_tz":-420,"elapsed":793,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!unzip \"face-mark\" -d 'face-m'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmqMzUs2vLVk","executionInfo":{"status":"ok","timestamp":1708613137013,"user_tz":-420,"elapsed":6,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"5fbd091a-9a54-4fe7-8a45-69e64d6a149a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  face-mark\n","  inflating: face-m/1 (1).jpg        \n","  inflating: face-m/1 (10).jpg       \n","  inflating: face-m/1 (100).jpg      \n","  inflating: face-m/1 (11).jpg       \n","  inflating: face-m/1 (12).jpg       \n","  inflating: face-m/1 (13).jpg       \n","  inflating: face-m/1 (14).jpg       \n","  inflating: face-m/1 (15).jpg       \n","  inflating: face-m/1 (16).jpg       \n","  inflating: face-m/1 (17).jpg       \n","  inflating: face-m/1 (18).jpg       \n","  inflating: face-m/1 (19).jpg       \n","  inflating: face-m/1 (2).jpg        \n","  inflating: face-m/1 (20).jpg       \n","  inflating: face-m/1 (21).jpg       \n","  inflating: face-m/1 (22).jpg       \n","  inflating: face-m/1 (23).jpg       \n","  inflating: face-m/1 (24).jpg       \n","  inflating: face-m/1 (25).jpg       \n","  inflating: face-m/1 (26).jpg       \n","  inflating: face-m/1 (27).jpg       \n","  inflating: face-m/1 (28).jpg       \n","  inflating: face-m/1 (29).jpg       \n","  inflating: face-m/1 (3).jpg        \n","  inflating: face-m/1 (30).jpg       \n","  inflating: face-m/1 (31).jpg       \n","  inflating: face-m/1 (32).jpg       \n","  inflating: face-m/1 (33).jpg       \n","  inflating: face-m/1 (34).jpg       \n","  inflating: face-m/1 (35).jpg       \n","  inflating: face-m/1 (36).jpg       \n","  inflating: face-m/1 (37).jpg       \n","  inflating: face-m/1 (38).jpg       \n","  inflating: face-m/1 (39).jpg       \n","  inflating: face-m/1 (4).jpg        \n","  inflating: face-m/1 (40).jpg       \n","  inflating: face-m/1 (41).jpg       \n","  inflating: face-m/1 (42).jpg       \n","  inflating: face-m/1 (43).jpg       \n","  inflating: face-m/1 (44).jpg       \n","  inflating: face-m/1 (45).jpg       \n","  inflating: face-m/1 (46).jpg       \n","  inflating: face-m/1 (47).jpg       \n","  inflating: face-m/1 (48).jpg       \n","  inflating: face-m/1 (49).jpg       \n","  inflating: face-m/1 (5).jpg        \n","  inflating: face-m/1 (50).jpg       \n","  inflating: face-m/1 (51).jpg       \n","  inflating: face-m/1 (52).jpg       \n","  inflating: face-m/1 (53).jpg       \n","  inflating: face-m/1 (54).jpg       \n","  inflating: face-m/1 (55).jpg       \n","  inflating: face-m/1 (56).jpg       \n","  inflating: face-m/1 (57).jpg       \n","  inflating: face-m/1 (58).jpg       \n","  inflating: face-m/1 (59).jpg       \n","  inflating: face-m/1 (6).jpg        \n","  inflating: face-m/1 (60).jpg       \n","  inflating: face-m/1 (61).jpg       \n","  inflating: face-m/1 (62).jpg       \n","  inflating: face-m/1 (63).jpg       \n","  inflating: face-m/1 (64).jpg       \n","  inflating: face-m/1 (65).jpg       \n","  inflating: face-m/1 (66).jpg       \n","  inflating: face-m/1 (67).jpg       \n","  inflating: face-m/1 (68).jpg       \n","  inflating: face-m/1 (69).jpg       \n","  inflating: face-m/1 (7).jpg        \n","  inflating: face-m/1 (70).jpg       \n","  inflating: face-m/1 (71).jpg       \n","  inflating: face-m/1 (72).jpg       \n","  inflating: face-m/1 (73).jpg       \n","  inflating: face-m/1 (74).jpg       \n","  inflating: face-m/1 (75).jpg       \n","  inflating: face-m/1 (76).jpg       \n","  inflating: face-m/1 (77).jpg       \n","  inflating: face-m/1 (78).jpg       \n","  inflating: face-m/1 (79).jpg       \n","  inflating: face-m/1 (8).jpg        \n","  inflating: face-m/1 (80).jpg       \n","  inflating: face-m/1 (81).jpg       \n","  inflating: face-m/1 (82).jpg       \n","  inflating: face-m/1 (83).jpg       \n","  inflating: face-m/1 (84).jpg       \n","  inflating: face-m/1 (85).jpg       \n","  inflating: face-m/1 (86).jpg       \n","  inflating: face-m/1 (87).jpg       \n","  inflating: face-m/1 (88).jpg       \n","  inflating: face-m/1 (89).jpg       \n","  inflating: face-m/1 (9).jpg        \n","  inflating: face-m/1 (90).jpg       \n","  inflating: face-m/1 (91).jpg       \n","  inflating: face-m/1 (92).jpg       \n","  inflating: face-m/1 (93).jpg       \n","  inflating: face-m/1 (94).jpg       \n","  inflating: face-m/1 (95).jpg       \n","  inflating: face-m/1 (96).jpg       \n","  inflating: face-m/1 (97).jpg       \n","  inflating: face-m/1 (98).jpg       \n","  inflating: face-m/1 (99).jpg       \n"]}]},{"cell_type":"markdown","source":["## Initialize Model"],"metadata":{"id":"rI2Vgh-f3z9c"}},{"cell_type":"code","source":["DATA_DIR = \"image/LaPa\"\n","DEVICE = 'cpu'\n","ENCODER = 'mobilenet_v2'\n","WEIGHTS = 'imagenet'\n","IMAGE_SIZE = 224\n","num_classes = 11\n","BATCH_SIZE = 64"],"metadata":{"id":"dGGRuVzH3mze","executionInfo":{"status":"ok","timestamp":1708613137013,"user_tz":-420,"elapsed":2,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# loading model from drive"],"metadata":{"id":"CDd540hZdlya"}},{"cell_type":"code","source":["!gdown --id \"1-MzlRCABoTDNtOCyIM37A611e2Lpjh8u\" -O \"best_model\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuyQF8Hu3rxD","executionInfo":{"status":"ok","timestamp":1708613141359,"user_tz":-420,"elapsed":4348,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"c561f22e-d2a5-4586-925e-1e064a980495"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1-MzlRCABoTDNtOCyIM37A611e2Lpjh8u\n","To: /content/best_model\n","100% 17.8M/17.8M [00:00<00:00, 158MB/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3c2YYCc9Lr6q","executionInfo":{"status":"ok","timestamp":1708613141359,"user_tz":-420,"elapsed":6,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class SegmentationModel(nn.Module):\n","  def __init__(self):\n","    super(SegmentationModel,self).__init__()\n","\n","    self.arc = smp.DeepLabV3Plus(\n","        encoder_name = ENCODER,\n","        encoder_weights = WEIGHTS,\n","        in_channels = 3,\n","        classes = num_classes,\n","        activation = None\n","    )\n","    for param in self.arc.encoder.parameters():\n","        param.requires_grad = False\n","  def forward(self, images, masks = None):\n","    logits = self.arc(images)\n","\n","    if masks != None:\n","      loss1 = DiceLoss(mode=\"multiclass\")(logits,masks)\n","      loss2 = nn.CrossEntropyLoss()(logits,masks)\n","      return logits, loss1 + loss2\n","\n","\n","    return logits"],"metadata":{"id":"PqvGGHd53_z8","executionInfo":{"status":"ok","timestamp":1708617902724,"user_tz":-420,"elapsed":4,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["model = SegmentationModel()\n","model.to(DEVICE)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Siu307Rz4NT7","executionInfo":{"status":"ok","timestamp":1708617903138,"user_tz":-420,"elapsed":4,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"e47b1dc4-7aa6-4fac-be44-76e904e76c83"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SegmentationModel(\n","  (arc): DeepLabV3Plus(\n","    (encoder): MobileNetV2Encoder(\n","      (features): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (4): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (5): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (6): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (7): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (8): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (9): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (10): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (11): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (12): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (13): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (14): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (15): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (16): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (17): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (18): Conv2dNormActivation(\n","          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","      )\n","    )\n","    (decoder): DeepLabV3PlusDecoder(\n","      (aspp): Sequential(\n","        (0): ASPP(\n","          (convs): ModuleList(\n","            (0): Sequential(\n","              (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (1): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (2): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (3): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (4): ASPPPooling(\n","              (0): AdaptiveAvgPool2d(output_size=1)\n","              (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (3): ReLU()\n","            )\n","          )\n","          (project): Sequential(\n","            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU()\n","            (3): Dropout(p=0.5, inplace=False)\n","          )\n","        )\n","        (1): SeparableConv2d(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU()\n","      )\n","      (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (block1): Sequential(\n","        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (block2): Sequential(\n","        (0): SeparableConv2d(\n","          (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n","          (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (segmentation_head): SegmentationHead(\n","      (0): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n","      (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["# load directly from my drive or you can load model parameter from disk in colab if !wget work"],"metadata":{"id":"-Lmac7pDdpjT"}},{"cell_type":"code","source":["model_name =  \"model4\""],"metadata":{"id":"Dw8rQrDn9ivf","executionInfo":{"status":"ok","timestamp":1708617907665,"user_tz":-420,"elapsed":376,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(f'gdrive/MyDrive/{model_name}.pt',map_location=torch.device(DEVICE)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PooShVhFqwM","executionInfo":{"status":"ok","timestamp":1708617911127,"user_tz":-420,"elapsed":2260,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"da774c77-ec5a-496a-84db-fbf0c0d78ea5"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["from torchsummary import summary\n","summary(model, (3, IMAGE_SIZE, IMAGE_SIZE))"],"metadata":{"id":"FqkDQBgX4w9u","executionInfo":{"status":"ok","timestamp":1708617911522,"user_tz":-420,"elapsed":401,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"21187736-3810-4bed-adf3-7840dfe412ad"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 112, 112]             864\n","       BatchNorm2d-2         [-1, 32, 112, 112]              64\n","             ReLU6-3         [-1, 32, 112, 112]               0\n","            Conv2d-4         [-1, 32, 112, 112]             288\n","       BatchNorm2d-5         [-1, 32, 112, 112]              64\n","             ReLU6-6         [-1, 32, 112, 112]               0\n","            Conv2d-7         [-1, 16, 112, 112]             512\n","       BatchNorm2d-8         [-1, 16, 112, 112]              32\n","  InvertedResidual-9         [-1, 16, 112, 112]               0\n","           Conv2d-10         [-1, 96, 112, 112]           1,536\n","      BatchNorm2d-11         [-1, 96, 112, 112]             192\n","            ReLU6-12         [-1, 96, 112, 112]               0\n","           Conv2d-13           [-1, 96, 56, 56]             864\n","      BatchNorm2d-14           [-1, 96, 56, 56]             192\n","            ReLU6-15           [-1, 96, 56, 56]               0\n","           Conv2d-16           [-1, 24, 56, 56]           2,304\n","      BatchNorm2d-17           [-1, 24, 56, 56]              48\n"," InvertedResidual-18           [-1, 24, 56, 56]               0\n","           Conv2d-19          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-20          [-1, 144, 56, 56]             288\n","            ReLU6-21          [-1, 144, 56, 56]               0\n","           Conv2d-22          [-1, 144, 56, 56]           1,296\n","      BatchNorm2d-23          [-1, 144, 56, 56]             288\n","            ReLU6-24          [-1, 144, 56, 56]               0\n","           Conv2d-25           [-1, 24, 56, 56]           3,456\n","      BatchNorm2d-26           [-1, 24, 56, 56]              48\n"," InvertedResidual-27           [-1, 24, 56, 56]               0\n","           Conv2d-28          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-29          [-1, 144, 56, 56]             288\n","            ReLU6-30          [-1, 144, 56, 56]               0\n","           Conv2d-31          [-1, 144, 28, 28]           1,296\n","      BatchNorm2d-32          [-1, 144, 28, 28]             288\n","            ReLU6-33          [-1, 144, 28, 28]               0\n","           Conv2d-34           [-1, 32, 28, 28]           4,608\n","      BatchNorm2d-35           [-1, 32, 28, 28]              64\n"," InvertedResidual-36           [-1, 32, 28, 28]               0\n","           Conv2d-37          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-38          [-1, 192, 28, 28]             384\n","            ReLU6-39          [-1, 192, 28, 28]               0\n","           Conv2d-40          [-1, 192, 28, 28]           1,728\n","      BatchNorm2d-41          [-1, 192, 28, 28]             384\n","            ReLU6-42          [-1, 192, 28, 28]               0\n","           Conv2d-43           [-1, 32, 28, 28]           6,144\n","      BatchNorm2d-44           [-1, 32, 28, 28]              64\n"," InvertedResidual-45           [-1, 32, 28, 28]               0\n","           Conv2d-46          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-47          [-1, 192, 28, 28]             384\n","            ReLU6-48          [-1, 192, 28, 28]               0\n","           Conv2d-49          [-1, 192, 28, 28]           1,728\n","      BatchNorm2d-50          [-1, 192, 28, 28]             384\n","            ReLU6-51          [-1, 192, 28, 28]               0\n","           Conv2d-52           [-1, 32, 28, 28]           6,144\n","      BatchNorm2d-53           [-1, 32, 28, 28]              64\n"," InvertedResidual-54           [-1, 32, 28, 28]               0\n","           Conv2d-55          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-56          [-1, 192, 28, 28]             384\n","            ReLU6-57          [-1, 192, 28, 28]               0\n","           Conv2d-58          [-1, 192, 14, 14]           1,728\n","      BatchNorm2d-59          [-1, 192, 14, 14]             384\n","            ReLU6-60          [-1, 192, 14, 14]               0\n","           Conv2d-61           [-1, 64, 14, 14]          12,288\n","      BatchNorm2d-62           [-1, 64, 14, 14]             128\n"," InvertedResidual-63           [-1, 64, 14, 14]               0\n","           Conv2d-64          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-65          [-1, 384, 14, 14]             768\n","            ReLU6-66          [-1, 384, 14, 14]               0\n","           Conv2d-67          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-68          [-1, 384, 14, 14]             768\n","            ReLU6-69          [-1, 384, 14, 14]               0\n","           Conv2d-70           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-71           [-1, 64, 14, 14]             128\n"," InvertedResidual-72           [-1, 64, 14, 14]               0\n","           Conv2d-73          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-74          [-1, 384, 14, 14]             768\n","            ReLU6-75          [-1, 384, 14, 14]               0\n","           Conv2d-76          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-77          [-1, 384, 14, 14]             768\n","            ReLU6-78          [-1, 384, 14, 14]               0\n","           Conv2d-79           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-80           [-1, 64, 14, 14]             128\n"," InvertedResidual-81           [-1, 64, 14, 14]               0\n","           Conv2d-82          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-83          [-1, 384, 14, 14]             768\n","            ReLU6-84          [-1, 384, 14, 14]               0\n","           Conv2d-85          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-86          [-1, 384, 14, 14]             768\n","            ReLU6-87          [-1, 384, 14, 14]               0\n","           Conv2d-88           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-89           [-1, 64, 14, 14]             128\n"," InvertedResidual-90           [-1, 64, 14, 14]               0\n","           Conv2d-91          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-92          [-1, 384, 14, 14]             768\n","            ReLU6-93          [-1, 384, 14, 14]               0\n","           Conv2d-94          [-1, 384, 14, 14]           3,456\n","      BatchNorm2d-95          [-1, 384, 14, 14]             768\n","            ReLU6-96          [-1, 384, 14, 14]               0\n","           Conv2d-97           [-1, 96, 14, 14]          36,864\n","      BatchNorm2d-98           [-1, 96, 14, 14]             192\n"," InvertedResidual-99           [-1, 96, 14, 14]               0\n","          Conv2d-100          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n","           ReLU6-102          [-1, 576, 14, 14]               0\n","          Conv2d-103          [-1, 576, 14, 14]           5,184\n","     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n","           ReLU6-105          [-1, 576, 14, 14]               0\n","          Conv2d-106           [-1, 96, 14, 14]          55,296\n","     BatchNorm2d-107           [-1, 96, 14, 14]             192\n","InvertedResidual-108           [-1, 96, 14, 14]               0\n","          Conv2d-109          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n","           ReLU6-111          [-1, 576, 14, 14]               0\n","          Conv2d-112          [-1, 576, 14, 14]           5,184\n","     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n","           ReLU6-114          [-1, 576, 14, 14]               0\n","          Conv2d-115           [-1, 96, 14, 14]          55,296\n","     BatchNorm2d-116           [-1, 96, 14, 14]             192\n","InvertedResidual-117           [-1, 96, 14, 14]               0\n","          Conv2d-118          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n","           ReLU6-120          [-1, 576, 14, 14]               0\n","          Conv2d-121          [-1, 576, 14, 14]           5,184\n","     BatchNorm2d-122          [-1, 576, 14, 14]           1,152\n","           ReLU6-123          [-1, 576, 14, 14]               0\n","          Conv2d-124          [-1, 160, 14, 14]          92,160\n","     BatchNorm2d-125          [-1, 160, 14, 14]             320\n","InvertedResidual-126          [-1, 160, 14, 14]               0\n","          Conv2d-127          [-1, 960, 14, 14]         153,600\n","     BatchNorm2d-128          [-1, 960, 14, 14]           1,920\n","           ReLU6-129          [-1, 960, 14, 14]               0\n","          Conv2d-130          [-1, 960, 14, 14]           8,640\n","     BatchNorm2d-131          [-1, 960, 14, 14]           1,920\n","           ReLU6-132          [-1, 960, 14, 14]               0\n","          Conv2d-133          [-1, 160, 14, 14]         153,600\n","     BatchNorm2d-134          [-1, 160, 14, 14]             320\n","InvertedResidual-135          [-1, 160, 14, 14]               0\n","          Conv2d-136          [-1, 960, 14, 14]         153,600\n","     BatchNorm2d-137          [-1, 960, 14, 14]           1,920\n","           ReLU6-138          [-1, 960, 14, 14]               0\n","          Conv2d-139          [-1, 960, 14, 14]           8,640\n","     BatchNorm2d-140          [-1, 960, 14, 14]           1,920\n","           ReLU6-141          [-1, 960, 14, 14]               0\n","          Conv2d-142          [-1, 160, 14, 14]         153,600\n","     BatchNorm2d-143          [-1, 160, 14, 14]             320\n","InvertedResidual-144          [-1, 160, 14, 14]               0\n","          Conv2d-145          [-1, 960, 14, 14]         153,600\n","     BatchNorm2d-146          [-1, 960, 14, 14]           1,920\n","           ReLU6-147          [-1, 960, 14, 14]               0\n","          Conv2d-148          [-1, 960, 14, 14]           8,640\n","     BatchNorm2d-149          [-1, 960, 14, 14]           1,920\n","           ReLU6-150          [-1, 960, 14, 14]               0\n","          Conv2d-151          [-1, 320, 14, 14]         307,200\n","     BatchNorm2d-152          [-1, 320, 14, 14]             640\n","InvertedResidual-153          [-1, 320, 14, 14]               0\n","          Conv2d-154         [-1, 1280, 14, 14]         409,600\n","     BatchNorm2d-155         [-1, 1280, 14, 14]           2,560\n","           ReLU6-156         [-1, 1280, 14, 14]               0\n","MobileNetV2Encoder-157  [[-1, 3, 224, 224], [-1, 16, 112, 112], [-1, 24, 56, 56], [-1, 32, 28, 28], [-1, 96, 14, 14], [-1, 1280, 14, 14]]               0\n","          Conv2d-158          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-159          [-1, 256, 14, 14]             512\n","            ReLU-160          [-1, 256, 14, 14]               0\n","          Conv2d-161         [-1, 1280, 14, 14]          11,520\n","          Conv2d-162          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-163          [-1, 256, 14, 14]             512\n","            ReLU-164          [-1, 256, 14, 14]               0\n","          Conv2d-165         [-1, 1280, 14, 14]          11,520\n","          Conv2d-166          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-167          [-1, 256, 14, 14]             512\n","            ReLU-168          [-1, 256, 14, 14]               0\n","          Conv2d-169         [-1, 1280, 14, 14]          11,520\n","          Conv2d-170          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-171          [-1, 256, 14, 14]             512\n","            ReLU-172          [-1, 256, 14, 14]               0\n","AdaptiveAvgPool2d-173           [-1, 1280, 1, 1]               0\n","          Conv2d-174            [-1, 256, 1, 1]         327,680\n","     BatchNorm2d-175            [-1, 256, 1, 1]             512\n","            ReLU-176            [-1, 256, 1, 1]               0\n","          Conv2d-177          [-1, 256, 14, 14]         327,680\n","     BatchNorm2d-178          [-1, 256, 14, 14]             512\n","            ReLU-179          [-1, 256, 14, 14]               0\n","         Dropout-180          [-1, 256, 14, 14]               0\n","            ASPP-181          [-1, 256, 14, 14]               0\n","          Conv2d-182          [-1, 256, 14, 14]           2,304\n","          Conv2d-183          [-1, 256, 14, 14]          65,536\n","     BatchNorm2d-184          [-1, 256, 14, 14]             512\n","            ReLU-185          [-1, 256, 14, 14]               0\n","UpsamplingBilinear2d-186          [-1, 256, 56, 56]               0\n","          Conv2d-187           [-1, 48, 56, 56]           1,152\n","     BatchNorm2d-188           [-1, 48, 56, 56]              96\n","            ReLU-189           [-1, 48, 56, 56]               0\n","          Conv2d-190          [-1, 304, 56, 56]           2,736\n","          Conv2d-191          [-1, 256, 56, 56]          77,824\n","     BatchNorm2d-192          [-1, 256, 56, 56]             512\n","            ReLU-193          [-1, 256, 56, 56]               0\n","DeepLabV3PlusDecoder-194          [-1, 256, 56, 56]               0\n","          Conv2d-195           [-1, 11, 56, 56]           2,827\n","UpsamplingBilinear2d-196         [-1, 11, 224, 224]               0\n","        Identity-197         [-1, 11, 224, 224]               0\n","      Activation-198         [-1, 11, 224, 224]               0\n","   DeepLabV3Plus-199         [-1, 11, 224, 224]               0\n","================================================================\n","Total params: 4,381,083\n","Trainable params: 2,157,211\n","Non-trainable params: 2,223,872\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 27487790694653.41\n","Params size (MB): 16.71\n","Estimated Total Size (MB): 27487790694670.70\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["## custom function"],"metadata":{"id":"cm3Pe4CG6ufa"}},{"cell_type":"code","source":["def show_image(image,mask,pred_image = None):\n","\n","    if pred_image == None:\n","\n","        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n","\n","        ax1.set_title('IMAGE')\n","        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')\n","\n","        ax2.set_title('GROUND TRUTH')\n","        grayscale_images = torch.Tensor(np.argmax(mask.numpy(), axis=0) * (255 / (mask.shape[0] - 1)))\n","        ax2.imshow(grayscale_images.permute(0,1).squeeze(),cmap = 'gray')\n","\n","    elif pred_image != None :\n","\n","        f, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(10,5))\n","\n","        ax1.set_title('IMAGE')\n","        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')\n","\n","        ax2.set_title('GROUND TRUTH')\n","        grayscale_images = torch.Tensor(np.argmax(mask.numpy(), axis=0) * (255 / (mask.shape[0] - 1)))\n","        ax2.imshow(grayscale_images.permute(0,1).squeeze(),cmap = 'gray')\n","\n","        ax3.set_title('MODEL OUTPUT')\n","        pred_image = torch.Tensor(np.argmax(pred_image.numpy(), axis=0) * (255 / (pred_image.shape[0] - 1)))\n","        ax3.imshow(pred_image.permute(0,1).squeeze(),cmap = 'gray')"],"metadata":{"id":"YI0PBjxP6xYS","executionInfo":{"status":"ok","timestamp":1708617911522,"user_tz":-420,"elapsed":6,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate"],"metadata":{"id":"So0Ew5uK7xw5"}},{"cell_type":"code","source":["model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U5SDXQAbKAX4","executionInfo":{"status":"ok","timestamp":1708617911522,"user_tz":-420,"elapsed":5,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"0b85e4ed-3273-4d74-a410-923d9a275f94"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SegmentationModel(\n","  (arc): DeepLabV3Plus(\n","    (encoder): MobileNetV2Encoder(\n","      (features): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (4): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (5): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (6): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (7): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (8): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (9): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (10): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (11): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (12): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (13): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (14): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=576, bias=False)\n","              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (15): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (16): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (17): InvertedResidual(\n","          (conv): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=960, bias=False)\n","              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU6(inplace=True)\n","            )\n","            (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","            (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (18): Conv2dNormActivation(\n","          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n","          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","      )\n","    )\n","    (decoder): DeepLabV3PlusDecoder(\n","      (aspp): Sequential(\n","        (0): ASPP(\n","          (convs): ModuleList(\n","            (0): Sequential(\n","              (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (1): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (2): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (3): ASPPSeparableConv(\n","              (0): SeparableConv2d(\n","                (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=1280, bias=False)\n","                (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              )\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU()\n","            )\n","            (4): ASPPPooling(\n","              (0): AdaptiveAvgPool2d(output_size=1)\n","              (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (3): ReLU()\n","            )\n","          )\n","          (project): Sequential(\n","            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU()\n","            (3): Dropout(p=0.5, inplace=False)\n","          )\n","        )\n","        (1): SeparableConv2d(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU()\n","      )\n","      (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (block1): Sequential(\n","        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (block2): Sequential(\n","        (0): SeparableConv2d(\n","          (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n","          (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (segmentation_head): SegmentationHead(\n","      (0): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n","      (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n","      (2): Activation(\n","        (activation): Identity()\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["class 0 = background\n","\n","class 1 = skin\n","\n","class 2 = left brown\n","\n","class 3 = right brown\n","\n","class 4 = left eye\n","\n","class 5 = right eye\n","\n","class 6 = nose\n","\n","class 7 = upper lip\n","\n","class 8 = mouth\n","\n","class 9 = lower lip\n","\n","class 10 = hair"],"metadata":{"id":"YGa-HilKQGEl"}},{"cell_type":"markdown","source":["## Download shape_predictor"],"metadata":{"id":"EV6_GCOkEm0Y"}},{"cell_type":"code","source":["import dlib"],"metadata":{"id":"VXmIRa_bErqp","executionInfo":{"status":"ok","timestamp":1708613154880,"user_tz":-420,"elapsed":537,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["!wget https://github.com/italojs/facial-landmarks-recognition/archive/refs/heads/master.zip -O 'shape'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjVWAyuXEuaE","executionInfo":{"status":"ok","timestamp":1708613165399,"user_tz":-420,"elapsed":10521,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"08856274-6770-411e-c891-fe425fda5cdb"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-22 14:45:53--  https://github.com/italojs/facial-landmarks-recognition/archive/refs/heads/master.zip\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://codeload.github.com/italojs/facial-landmarks-recognition/zip/refs/heads/master [following]\n","--2024-02-22 14:45:53--  https://codeload.github.com/italojs/facial-landmarks-recognition/zip/refs/heads/master\n","Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n","Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘shape’\n","\n","shape                   [   <=>              ]  68.98M   165MB/s    in 0.4s    \n","\n","2024-02-22 14:46:03 (165 MB/s) - ‘shape’ saved [72327196]\n","\n"]}]},{"cell_type":"code","source":["!unzip 'shape' -d 'shape_pred'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2Bpae5QFMKp","executionInfo":{"status":"ok","timestamp":1708613166501,"user_tz":-420,"elapsed":1106,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"f413a581-4ee8-4d4f-e941-43362e2165b9"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  shape\n","d37b6a7426e98094e28fa99254e270a3e9b6d591\n","   creating: shape_pred/facial-landmarks-recognition-master/\n","  inflating: shape_pred/facial-landmarks-recognition-master/README.md  \n","  inflating: shape_pred/facial-landmarks-recognition-master/main.py  \n","  inflating: shape_pred/facial-landmarks-recognition-master/shape_predictor_68_face_landmarks.dat  \n"]}]},{"cell_type":"code","source":["predictor_path = '/content/shape_pred/facial-landmarks-recognition-master/shape_predictor_68_face_landmarks.dat'"],"metadata":{"id":"P7h324VJFVyx","executionInfo":{"status":"ok","timestamp":1708613166502,"user_tz":-420,"elapsed":3,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(predictor_path)"],"metadata":{"id":"ypJ82JxoFYq5","executionInfo":{"status":"ok","timestamp":1708613168143,"user_tz":-420,"elapsed":959,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["## Function"],"metadata":{"id":"XJ6HkpqpGDTZ"}},{"cell_type":"code","source":["total = list(range(0,68))\n","left_eye_indices = list(range(36, 42))\n","right_eye_indices = list(range(42, 48))\n","mouth_indices = list(range(48, 61))\n","smile_indices = list(range(48, 68))\n","\n","#PARAM\n","#use BGR which is blue / green / red\n","left_eye_color = [125,125,0]\n","#use BGR which is blue / green / red\n","right_eye_color = [0,125,125]\n","#use HSV which is hue value\n","mouth_h = 255\n","\n","#change/swap part of image\n","def add_part_image(full_img,part,mask):\n","    mask_inv = cv2.bitwise_not(mask)\n","    background = cv2.bitwise_and(full_img,full_img,mask = mask_inv)\n","    result = cv2.add(background,part)\n","    return result\n","\n","#change mouth tone color base on mask (if it black or white tone it won't change)\n","def change_mouth_color(bgr_img,mask,hue,logit_mouth,CURRENT_FACIAL):\n","    hsv_img = cv2.cvtColor(bgr_img,cv2.COLOR_BGR2HSV)\n","    my_mask = None\n","    if mask is not None:\n","        _,thresh = cv2.threshold(mask, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","        if (CURRENT_FACIAL is not None):\n","            CURRENT_FACIAL = cv2.bitwise_or(CURRENT_FACIAL,thresh)\n","        my_mask = cv2.bitwise_or(logit_mouth,mask)\n","    else:\n","        my_mask = logit_mouth\n","    h, s, v = cv2.split(hsv_img)\n","    h[my_mask == 255] = hue\n","    hsv_img = cv2.merge([h,s,v])\n","\n","    img = cv2.cvtColor(hsv_img,cv2.COLOR_HSV2BGR)\n","    return img , CURRENT_FACIAL\n","\n","#change iris eye base on mask\n","def change_iris_eye(bgr_img,mask,color,CURRENT_FACIAL):\n","    gray = cv2.cvtColor(bgr_img,cv2.COLOR_BGR2GRAY)\n","    gray = cv2.bitwise_and(gray,gray,mask = mask)\n","   # eye = cv2.bitwise_and(gray,gray,mask = mask)\n","    _,thresh = cv2.threshold(gray, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","    thresh = cv2.bitwise_and(thresh,thresh,mask = mask)\n","\n","    iris = bgr_img.copy()\n","    iris[:,:] = color\n","\n","    iris = cv2.bitwise_and(iris,iris,mask = thresh)\n","    if (CURRENT_FACIAL is not  None):\n","        CURRENT_FACIAL = cv2.add(CURRENT_FACIAL,thresh)\n","    #iris = cv2.bitwise_and(iris,iris,mask = mask)\n","\n","    result = add_part_image(bgr_img,iris,thresh)\n","    return result , CURRENT_FACIAL\n","\n","#get face mask\n","def get_face(gray,landmarks):\n","    mask = np.zeros_like(gray)\n","    points = np.array([(landmarks.part(n).x,landmarks.part(n).y) for n in total])\n","    hull = cv2.convexHull(points)\n","    cv2.fillConvexPoly(mask, hull,255)\n","    return mask\n","\n","#enhance face with mask\n","def enhance_face(hsv_img,result,mask):\n","    face_region = cv2.bitwise_and(hsv_img,hsv_img, mask = mask)\n","    face_region[:,:,2] = cv2.equalizeHist(face_region[:,:,2])\n","    face_region = cv2.cvtColor(face_region,cv2.COLOR_HSV2BGR)\n","    result = add_part_image(result,face_region,mask)\n","    return result\n","\n","#get mouth mask\n","def get_mouth(logit,WIDTH,HEIGHT):\n","    mouth0 = (logit.numpy().astype(np.uint8))[7,:,:]\n","    mouth1 = (logit.numpy().astype(np.uint8))[8,:,:]\n","    mouth2 = (logit.numpy().astype(np.uint8))[9,:,:]\n","\n","    _, mouth0 =  cv2.threshold(mouth0, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","    _, mouth1 =  cv2.threshold(mouth1, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","    _, mouth2 =  cv2.threshold(mouth2, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","\n","    mouth = mouth0\n","    mouth = cv2.bitwise_or(mouth,mouth1)\n","    mouth = cv2.bitwise_or(mouth,mouth2)\n","\n","    kernel = np.ones((5,5),np.uint8)\n","    mouth = cv2.morphologyEx(mouth,cv2.MORPH_OPEN,kernel,iterations = 1)\n","    mouth = cv2.resize(mouth,(WIDTH,HEIGHT))\n","\n","    return mouth\n","\n","\n","# combination of function to enhancement\n","def main(detector,predictor,frame,logit,logit_mouth,CURRENT_FACIAL,CURRENT_FACE):\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    faces = detector(gray)\n","    result = frame.copy()\n","    hsv_img = cv2.cvtColor(result,cv2.COLOR_BGR2HSV)\n","    B,G,R = cv2.split(result)\n","    laplacian = np.array([\n","        [0,-1,0],\n","        [-1,5,-1],\n","        [0,-1,0]\n","    ])\n","    blur_kernel = (5,5)\n","    B = cv2.GaussianBlur(B,blur_kernel,0)\n","    G = cv2.GaussianBlur(G,blur_kernel,0)\n","    R = cv2.GaussianBlur(R,blur_kernel,0)\n","\n","    R = cv2.medianBlur(R,3)\n","    G = cv2.medianBlur(G,3)\n","    B = cv2.medianBlur(B,3)\n","\n","    B = cv2.filter2D(B.astype(np.int16),-1,laplacian).clip(0,255).astype(np.uint8)\n","    G = cv2.filter2D(G.astype(np.int16),-1,laplacian).clip(0,255).astype(np.uint8)\n","    R = cv2.filter2D(R.astype(np.int16),-1,laplacian).clip(0,255).astype(np.uint8)\n","    result = cv2.merge([B,G,R])\n","    for face in faces:\n","        landmarks = predictor(gray, face)\n","        mask = get_face(gray,landmarks)\n","        if (CURRENT_FACE is not None):\n","            CURRENT_FACE = cv2.bitwise_or(CURRENT_FACE,mask)\n","        result = enhance_face(hsv_img,result,cv2.bitwise_or(mask,logit))\n","        left_eye = np.array([((landmarks.part(idx).x) , (landmarks.part(idx).y)) for idx in left_eye_indices])\n","        right_eye = np.array([((landmarks.part(idx).x) , (landmarks.part(idx).y)) for idx in right_eye_indices])\n","        mouth = np.array([((landmarks.part(idx).x) , (landmarks.part(idx).y)) for idx in mouth_indices])\n","        mask1 = np.zeros(frame.shape[:2],dtype=np.uint8)\n","        mask2 = np.zeros(frame.shape[:2],dtype=np.uint8)\n","        mask3 = np.zeros(frame.shape[:2],dtype=np.uint8)\n","        cv2.drawContours(mask1,[left_eye],-1, (255, 255, 255), -1, cv2.LINE_AA)\n","        cv2.drawContours(mask2,[right_eye],-1, (255, 255, 255), -1, cv2.LINE_AA)\n","        cv2.drawContours(mask3,[mouth],-1, (255, 255, 255), -1, cv2.LINE_AA)\n","\n","        result , CURRENT_FACIAL = change_mouth_color(result,mask3,mouth_h,logit_mouth,CURRENT_FACIAL)\n","        result , CURRENT_FACIAL = change_iris_eye(result,mask1,left_eye_color,CURRENT_FACIAL)\n","        result , CURRENT_FACIAL = change_iris_eye(result,mask2,right_eye_color,CURRENT_FACIAL)\n","    if (len(faces) == 0):\n","        result = enhance_face(hsv_img,result,logit)\n","        result , CURRENT_FACIAL = change_mouth_color(result,None,mouth_h,logit_mouth,CURRENT_FACIAL)\n","    return result , CURRENT_FACIAL , CURRENT_FACE\n","\n","#\n","def enhancer(image):\n","    HEIGHT,WIDTH = image.shape[:2]\n","\n","\n","    #initial combine result mask from method\n","    # get mask from model\n","    my_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    my_img = cv2.resize(my_img,(224,224))\n","    my_img = np.transpose(my_img, (2,0,1)).astype(np.float32)\n","    my_img = torch.Tensor(my_img) / 255.0\n","    logit = model(my_img.to(DEVICE).unsqueeze(0))\n","    my_logit = logit.detach().cpu().squeeze(0)\n","    my_logit = torch.softmax(my_logit,dim = 0)\n","    my_logit = torch.argmax(my_logit, dim=0)\n","\n","    my_logit = one_hot(my_logit,11)\n","    my_logit = my_logit.permute((2,0,1)) * 255.0\n","\n","    #get face\n","    mouth = get_mouth(my_logit,WIDTH,HEIGHT)\n","    nhair = (my_logit.numpy().astype(np.uint8))[10,:,:]\n","    face = (my_logit.numpy().astype(np.uint8))[0,:,:]\n","    _, nhair =  cv2.threshold(nhair, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","    _, face =  cv2.threshold(face, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","    mask_face = cv2.bitwise_and(nhair,face)\n","    kernel = np.ones((5,5),np.uint8)\n","    #remove noise\n","    mask_face = cv2.morphologyEx(mask_face,cv2.MORPH_OPEN,kernel,iterations = 1)\n","    mask_face = cv2.resize(mask_face,(WIDTH,HEIGHT))\n","    # result = main(detector,predictor,image)(detector,predictor,frame,logit,logit_mouth,CURRENT_FACIAL,CURRENT_FACE)\n","    result , CURRENT_FACIAL , CURRENT_FACE = main(detector,predictor,image,mask_face,mouth,None, None)\n","    result = cv2.cvtColor(result,cv2.COLOR_BGR2RGB)\n","\n","    return result"],"metadata":{"id":"W0c23z77GEjq","executionInfo":{"status":"ok","timestamp":1708617916037,"user_tz":-420,"elapsed":3,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-vl3KAHNpDG6","executionInfo":{"status":"ok","timestamp":1708617916444,"user_tz":-420,"elapsed":2,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["## Use Case"],"metadata":{"id":"BtaEWt9gEd2z"}},{"cell_type":"code","source":["def my_iou(predict,mask):\n","    predict = predict // 255\n","    mask = mask // 255\n","    intersection = np.sum(predict & mask)\n","    union = np.sum(predict | mask)\n","    return (intersection + 1e-10) / (union + 1e-10)"],"metadata":{"id":"r-Qe3LnLSf2q","executionInfo":{"status":"ok","timestamp":1708617916948,"user_tz":-420,"elapsed":12,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["### Eval"],"metadata":{"id":"3UvtZZblM_Y-"}},{"cell_type":"code","source":["path_img = '/content/archive'\n","path_markup = '/content/markup'\n","path_face_m = '/content/face-m'\n","score = np.zeros(100,dtype = np.float64)\n","fscore = np.zeros(100,dtype = np.float64)\n","psnr = np.zeros(100,dtype = np.float64)\n","c = 10\n","K = 0.0001\n","model.eval()\n","with torch.no_grad():\n","    for i in range(0,100):\n","        p = os.path.join(path_img,f'1 ({i + 1}).jpg')\n","        image = cv2.imread(p)\n","        HEIGHT,WIDTH = image.shape[:2]\n","        my_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        my_img = cv2.resize(my_img,(224,224))\n","        my_img = np.transpose(my_img, (2,0,1)).astype(np.float32)\n","        my_img = torch.Tensor(my_img) / 255.0\n","        logit = model(my_img.to(DEVICE).unsqueeze(0))\n","\n","        CURRENT_FACIAL = np.zeros((HEIGHT,WIDTH),dtype = np.uint8)\n","        CURRENT_FACE = np.zeros((HEIGHT,WIDTH),dtype = np.uint8)\n","\n","        my_logit = logit.detach().cpu().squeeze(0)\n","        my_logit = torch.softmax(my_logit, dim = 0)\n","        my_logit = torch.argmax(my_logit, dim=0)\n","\n","        my_logit = one_hot(my_logit,11)\n","        my_logit = my_logit.permute((2,0,1)) * 255.0\n","       # my_logit = (my_logit > 0.5) * 255.0\n","\n","        mouth = get_mouth(my_logit,WIDTH,HEIGHT)\n","        # get hair -> inv -> get all area that doesn't include hair\n","        nhair = (my_logit.numpy().astype(np.uint8))[10,:,:]\n","        # background -> inv -> get all area that not background(head of person)\n","        # when two mask use and bitwise will got all face that don't include hair\n","        face = (my_logit.numpy().astype(np.uint8))[0,:,:]\n","        # not hair will get\n","        _, nhair =  cv2.threshold(nhair, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","        # not background will get head area for all\n","        _, face =  cv2.threshold(face, 0 , 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n","        mask_face = cv2.bitwise_and(nhair,face)\n","        kernel = np.ones((5,5),np.uint8)\n","        mask_face = cv2.morphologyEx(mask_face,cv2.MORPH_OPEN,kernel,iterations = 1)\n","        mask_face = cv2.resize(mask_face,(WIDTH,HEIGHT))\n","\n","        p_markup = os.path.join(path_markup,f'1 ({i + 1}).jpg')\n","        markup = cv2.imread(p_markup,0)\n","        _, thresh =  cv2.threshold(markup, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","\n","        f_markup = os.path.join(path_face_m,f'1 ({i + 1}).jpg')\n","        fmarkup = cv2.imread(f_markup,0)\n","        _, fthresh =  cv2.threshold(fmarkup, 0 , 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n","        CURRENT_FACE = mask_face\n","        CURRENT_FACIAL = mouth\n","    # result = main(detector,predictor,image)\n","        result , CURRENT_FACIAL , CURRENT_FACE = main(detector,predictor,image,mask_face,mouth,CURRENT_FACIAL, CURRENT_FACE)\n","        result = cv2.cvtColor(result,cv2.COLOR_BGR2RGB)\n","        score[i] = my_iou(CURRENT_FACIAL,thresh)\n","        fscore[i] = my_iou(CURRENT_FACE,fthresh)\n","        original = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        print(f'facial enhance = {score[i]} , face enhance = { fscore[i]}')\n","        plt.figure(figsize=(14,6))\n","        plt.subplot(1,6,1)\n","        plt.imshow(original)\n","        plt.subplot(1,6,2)\n","        plt.imshow(result)\n","        plt.subplot(1,6,3)\n","        plt.imshow(CURRENT_FACIAL,cmap = 'gray')\n","        plt.subplot(1,6,4)\n","        plt.imshow(thresh, cmap = 'gray')\n","        plt.subplot(1,6,5)\n","        plt.imshow(CURRENT_FACE,cmap = 'gray')\n","        plt.subplot(1,6,6)\n","        plt.imshow(fthresh,cmap = 'gray')\n","        plt.show()\n","print(f'average iou = {np.mean(fscore)}')\n","print(f'average iou = {np.mean(score)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10PW39pXvGreML4cVCGkA4MEvXLVHWfLq"},"id":"ZV9vnzYHEfl8","executionInfo":{"status":"ok","timestamp":1708618081637,"user_tz":-420,"elapsed":163878,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"0edcfeb0-0412-41b0-c9cf-0d0854ff10f5"},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Save test result"],"metadata":{"id":"GhMmn6jy90Bw"}},{"cell_type":"code","source":["test = pd.DataFrame([np.mean(fscore),np.mean(score)],index = [\"Face enhancement\",\"Facial change color\"],columns = [\"mIoU score\"])\n","test.to_csv(f\"gdrive/MyDrive/{model_name}_result_enhancement.csv\")"],"metadata":{"id":"RvhUwUUC9Ji7","executionInfo":{"status":"ok","timestamp":1708618081638,"user_tz":-420,"elapsed":15,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["### Enhance random image"],"metadata":{"id":"PUXcur7lNAhH"}},{"cell_type":"code","source":["import random\n","path_img = '/content/archive'\n","path_markup = '/content/markup'\n","path_face_m = '/content/face-m'\n","c = 10\n","K = 0.0001\n","model.eval()\n","with torch.no_grad():\n","    for i in random.sample(range(0,100),5):\n","        p = os.path.join(path_img,f'1 ({i + 1}).jpg')\n","        image = cv2.imread(p)\n","        result = enhancer(image)\n","\n","        original = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        plt.figure(figsize=(14,6))\n","        plt.subplot(1,2,1)\n","        plt.imshow(original)\n","        plt.subplot(1,2,2)\n","        plt.imshow(result)\n","        plt.show()"],"metadata":{"id":"SPbCJir6QheA","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1oWU8uQpQMKrEZSJvbI9LJrp0fAgafTVt"},"executionInfo":{"status":"ok","timestamp":1708618091422,"user_tz":-420,"elapsed":5812,"user":{"displayName":"werapat wangrungrod","userId":"01106086328674120706"}},"outputId":"eed222fb-bb8e-4996-8875-e9500a097984"},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"NxKkGRNIuEH6"},"execution_count":null,"outputs":[]}]}